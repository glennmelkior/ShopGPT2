{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: \n",
    "- Import df\n",
    "- df = 'url', 'name', 'price', 'color', 'images', 'image link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  \\\n",
      "0  https://www.asos.com/new-look/new-look-trench-...   \n",
      "1  https://www.asos.com/stradivarius/stradivarius...   \n",
      "2  https://www.asos.com/jdy/jdy-oversized-trench-...   \n",
      "3  https://www.asos.com/nike-running/nike-running...   \n",
      "4  https://www.asos.com/asos-curve/asos-design-cu...   \n",
      "\n",
      "                                                name  price    color  \\\n",
      "0                      New Look trench coat in camel  49.99  Neutral   \n",
      "1     Stradivarius double breasted wool coat in grey  59.99     GREY   \n",
      "2                 JDY oversized trench coat in stone  45.00    STONE   \n",
      "3                 Nike Running hooded jacket in pink  84.95     Pink   \n",
      "4  ASOS DESIGN Tall linen mix trench coat in natural  75.00  Natural   \n",
      "\n",
      "                                              images  \\\n",
      "0  ['https://images.asos-media.com/products/new-l...   \n",
      "1  ['https://images.asos-media.com/products/strad...   \n",
      "2  ['https://images.asos-media.com/products/jdy-o...   \n",
      "3  ['https://images.asos-media.com/products/nike-...   \n",
      "4  ['https://images.asos-media.com/products/asos-...   \n",
      "\n",
      "                                          image link  \n",
      "0  https://images.asos-media.com/products/new-loo...  \n",
      "1  https://images.asos-media.com/products/stradiv...  \n",
      "2  https://images.asos-media.com/products/jdy-ove...  \n",
      "3  https://images.asos-media.com/products/nike-ru...  \n",
      "4  https://images.asos-media.com/products/asos-de...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CAREFUL WHEN REDUCING:\n",
    "#       Need to delete faiss_index.bin \n",
    "# downloaded = 500\n",
    "num_samples = 100\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./datasets/products.csv\").head(num_samples)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[['url', 'name', 'price', 'color', 'images', 'image link']]\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: (takes time)\n",
    "- Download image\n",
    "- Extract description\n",
    "- Generate description\n",
    "- Apply LLaVa\n",
    "- df = 'url', 'name', 'price', 'color', 'images', 'image link' + description, image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using existing description for New Look trench coat in camel\n",
      "âœ… Using existing description for Stradivarius double breasted wool coat in grey\n",
      "âœ… Using existing description for JDY oversized trench coat in stone\n",
      "âœ… Using existing description for Nike Running hooded jacket in pink\n",
      "âœ… Using existing description for ASOS DESIGN Tall linen mix trench coat in natural\n",
      "âœ… Using existing description for ASOS DESIGN denim bomber in ecru\n",
      "âœ… Using existing description for ASOS Weekend Collective nylon track jacket in neutral\n",
      "âœ… Using existing description for ASOS DESIGN Tall ultimate faux leather biker jacket in black\n",
      "âœ… Using existing description for Native Youth oversized twill shacket co-ord in purple\n",
      "âœ… Using existing description for Carhartt WIP michigan OG jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN denim short sleeve shirt in midwash blue\n",
      "âœ… Using existing description for Bershka maxi belted coat in black\n",
      "âœ… Using existing description for Vero Moda trench coat in black\n",
      "âœ… Using existing description for Stradivarius tailored coat in beige\n",
      "âœ… Using existing description for Stradivarius tailored belted coat in black\n",
      "âœ… Using existing description for Miss Selfridge longline faux leather biker jacket in black\n",
      "âœ… Using existing description for Bershka faux leather motorcross jacket in light grey\n",
      "âœ… Using existing description for Bershka oversized bomber puffer jacket in black\n",
      "âœ… Using existing description for Topshop denim balloon jacket in dirty dark wash\n",
      "âœ… Using existing description for Barbour Annandale diamond quilt jacket with cord collar in navy\n",
      "âœ… Using existing description for ASOS DESIGN borg denim jacket in washed blue\n",
      "âœ… Using existing description for Vero Moda hooded rain jacket in black\n",
      "âœ… Using existing description for New Look Tall trench coat in camel\n",
      "âœ… Using existing description for ASOS DESIGN Petite smart dad coat in black\n",
      "âœ… Using existing description for ASOS DESIGN overhead rain jacket in khaki\n",
      "âœ… Using existing description for New Look quilted belted trench coat in black\n",
      "âœ… Using existing description for ASOS DESIGN high shine bomber jacket in cobalt\n",
      "âœ… Using existing description for New Look mid length padded puffer coat with hood in dark khaki\n",
      "âœ… Using existing description for ASOS DESIGN Curve herringbone shacket in oatmeal\n",
      "âœ… Using existing description for Bershka athletic track jacket in navy\n",
      "âœ… Using existing description for Topshop longline chuck on coat in black\n",
      "âœ… Using existing description for Aria Cove vegan leather trench coat in khaki\n",
      "âœ… Using existing description for Bershka tailored double breasted coat in ecru\n",
      "âœ… Using existing description for ASOS DESIGN Petite trench coat with faux leather hood in black\n",
      "âœ… Using existing description for Under Armour Training Meridian jacket in black\n",
      "âœ… Using existing description for Pull&Bear oversized  bomber jacket in grey\n",
      "âœ… Using existing description for ASOS DESIGN Curve oversized rain parka in black\n",
      "âœ… Using existing description for ASOS 4505 mid layer fleece back jacket with reflective piping\n",
      "âœ… Using existing description for Topshop double breasted coat in green\n",
      "âœ… Using existing description for Topshop Sno borg zip through jacket in green\n",
      "âœ… Using existing description for New Look belted gilet with tie waist detail in light khaki\n",
      "âœ… Using existing description for New Look Curve quilted puffer coat in dark khaki\n",
      "âœ… Using existing description for Topshop Tall sleeveless puffer gilet jacket in off white\n",
      "âœ… Using existing description for Forever New formal wrap coat with tie belt in camel\n",
      "âœ… Using existing description for Topshop oversized collar corduroy bomber jacket in beige\n",
      "âœ… Using existing description for ASOS DESIGN Tall cotton pocket shacket in black\n",
      "âœ… Using existing description for Vero Moda belted wrap coat in beige\n",
      "âœ… Using existing description for In The Style utility pocket detail belted jacket in blue\n",
      "âœ… Using existing description for Noisy May cord oversized shacket in brown\n",
      "âœ… Using existing description for ASOS DESIGN leather ultimate biker jacket in black\n",
      "âœ… Using existing description for Gym King utility gilet in black\n",
      "âœ… Using existing description for River Island faux leather oversized biker jacket in black\n",
      "âœ… Using existing description for Tommy Jeans oversized hooded denim jacket in multi\n",
      "âœ… Using existing description for Topshop textured short coat in grey\n",
      "âœ… Using existing description for NA-KD x Moa Mattsson belted trench coat with faux fur in sage\n",
      "âœ… Using existing description for Topshop borg trench coat in grey\n",
      "âœ… Using existing description for Whistles quilted jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN Petite rubberised rain parka coat in black\n",
      "âœ… Using existing description for Pull&Bear puffer coat with hood in grey\n",
      "âœ… Using existing description for The Frolic tweed boucle cropped jacket co-ord in multi\n",
      "âœ… Using existing description for Topshop Tall faux leather shearling aviator biker jacket in ecru\n",
      "âœ… Using existing description for Topshop mid length tie belted puffer jacket in forest green\n",
      "âœ… Using existing description for Stradivarius STR faux leather fur trim coat in brown\n",
      "âœ… Using existing description for ASOS EDITION hooded trench coat in khaki\n",
      "âœ… Using existing description for Miss Selfridge Petite cropped denim jacket in midwash blue\n",
      "âœ… Using existing description for River Island herringbone duster coat in dark grey\n",
      "âœ… Using existing description for Stradivarius padded puffer jacket in ecru\n",
      "âœ… Using existing description for Weekday Daphne double breasted formal maxi coat in dark grey\n",
      "âœ… Using existing description for ASOS DESIGN Petite cropped rain jacket with hood in black\n",
      "âœ… Using existing description for Only longline formal coat in chocolate\n",
      "âœ… Using existing description for Bershka longline shearling coat in brown\n",
      "âœ… Using existing description for Forever New formal cocoon coat in emerald green\n",
      "âœ… Using existing description for Noisy May Petite longline padded coat with hood in black\n",
      "âœ… Using existing description for Only trench coat in brown check\n",
      "âœ… Using existing description for Topshop Dad denim jacket in bleach\n",
      "âœ… Using existing description for Topshop Tailored double layered funnel neck trench in sage\n",
      "âœ… Using existing description for Vero Moda Tall coated jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN washed premium real leather biker jacket in grey\n",
      "âœ… Using existing description for River Island oversized coat in cream\n",
      "âœ… Using existing description for Topshop Tilda western denim jacket in mid blue\n",
      "âœ… Using existing description for Topshop faux leather trench coat in dark chocolate\n",
      "âœ… Using existing description for NA-KD x Angelica Blick faux leather trench coat in blue\n",
      "âœ… Using existing description for Crooked Tongues x Felix the Cat Unisex varsity jacket in black\n",
      "âœ… Using existing description for Topshop faux leather cropped car coat with faux fur trims in chocolate\n",
      "âœ… Using existing description for Bershka tailored coat in blue\n",
      "âœ… Using existing description for Bershka faux leather racer jacket in blue & white\n",
      "âœ… Using existing description for Selected Femme long line trench coat in beige\n",
      "âœ… Using existing description for Only Tall longline tailored coat in stone\n",
      "âœ… Using existing description for Pull&Bear oversized motorcycle jacket in navy with contrast navy and yellow pannels\n",
      "âœ… Using existing description for Missguided faux leather puffer jacket in white\n",
      "âœ… Using existing description for Reclaimed Vintage longline puffer coat with faux fur detail in black\n",
      "âœ… Using existing description for New Look Tall mid length hooded puffer coat in black\n",
      "âœ… Using existing description for In The Style belted trench coat in beige\n",
      "âœ… Using existing description for Topshop Tall chuck on coat in oat\n",
      "âœ… Using existing description for COLLUSION shaggy faux mongolian fur jacket in cream\n",
      "âœ… Using existing description for Stradivarius tailored belted coat in camel\n",
      "âœ… Using existing description for Stradivarius brushed shacket in ecru\n",
      "âœ… Using existing description for Pimkie double breasted longline coat in brown\n",
      "âœ… Using existing description for ASOS DESIGN longline trench coat in khaki\n",
      "âœ… Using existing description for ASOS DESIGN Petite rubberised rain parka in stone\n",
      "Descriptions generated and saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import shlex \n",
    "import re\n",
    "\n",
    "# Define LLaVA paths (modify these based on your system)\n",
    "LLAVA_CLI_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/llama-llava-cli\"\n",
    "LLAVA_MODEL_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llava-v1.6-mistral-7b/Mistral-7B-Instruct-v0.2-F32-Q4_K_M.gguf\"\n",
    "MM_PROJ_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/vit/mmproj-model-f16.gguf\"\n",
    "IMAGES_DATA = \"./images_data\"\n",
    "DESCRIPTIONS_DATA = \"./descriptions_data\"\n",
    "\n",
    "# Ensure temp directory exists\n",
    "os.makedirs(IMAGES_DATA, exist_ok=True)\n",
    "os.makedirs(DESCRIPTIONS_DATA, exist_ok=True)\n",
    "\n",
    "def download_image(image_url, filename):\n",
    "    \"\"\"Downloads an image from a URL if it doesn't already exist.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Image already exists: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    \"\"\"Downloads an image from a URL and saves it locally.\"\"\"\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "        return filename\n",
    "    else:\n",
    "        print(f\"Failed to download image: {image_url}\")\n",
    "        return None\n",
    "\n",
    "def extract_description(output_file):\n",
    "    \"\"\"Extracts only the relevant product description from LLaVA output.\"\"\"\n",
    "    with open(output_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the starting point of the description\n",
    "    start_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"encode_image_with_clip: image encoded\" in line:\n",
    "            start_index = i + 1  # Description starts on the next line\n",
    "            break\n",
    "\n",
    "    # Extract everything after the start_index\n",
    "    if start_index is not None and start_index < len(lines):\n",
    "        return \" \".join(lines[start_index:]).strip()\n",
    "    else:\n",
    "        return \"Description not found\"\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Replaces special characters that are invalid in filenames.\"\"\"\n",
    "    name = name.replace(' ', '_')  # Replace spaces with underscores\n",
    "    return re.sub(r'[\\\\/:\"*?<>|]', '_', name)  # Replace `/ \\ : \" * ? < > |` with `_`\n",
    "\n",
    "def generate_description(image_url, name, color):\n",
    "    \"\"\"Generates a textual description using LLaVA for a given fashion product image.\"\"\"\n",
    "    safe_name = sanitize_filename(name)\n",
    "    image_path = os.path.join(IMAGES_DATA, f\"{safe_name}.jpg\")\n",
    "    description_path = os.path.join(DESCRIPTIONS_DATA, f\"{safe_name}.txt\")\n",
    "\n",
    "    # If description file already exists, read from it\n",
    "    if os.path.exists(description_path):\n",
    "        with open(description_path, \"r\") as file:\n",
    "            existing_description = file.read().strip()\n",
    "\n",
    "        if existing_description and existing_description != \"Description not found\":\n",
    "            print(f\"âœ… Using existing description for {name}\")\n",
    "            return existing_description\n",
    "        else:\n",
    "            print(f\"ðŸ”„ Regenerating description for {name} (previously invalid)\")\n",
    "\n",
    "        # print(f\"Reading existing description for {name}\")\n",
    "        # return open(description_path, \"r\").read()\n",
    "\n",
    "    downloaded_image = download_image(image_url, image_path)\n",
    "    if not downloaded_image:\n",
    "        return \"Image not available\"\n",
    "    \n",
    "    output_file = \"llava_output.txt\"\n",
    "    \n",
    "#     prompt = f\"\"\"{image_path}\n",
    "# USER:\n",
    "# Describe the {color} {name} in this image in detail.\n",
    "# - Focus on its fabric, style, and patterns.\n",
    "# - Ignore other clothing items other than {color} {name} in the image.\n",
    "# - Do NOT add any extra information other than the description.\n",
    "# - Write the response as a single detailed paragraph. Do not use bullet points.\n",
    "# - Avoid listing features separately; instead, describe the product naturally in a flowing sentence.\n",
    "\n",
    "# ASSISTANT:\n",
    "# \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "USER:\n",
    "Describe the {color} {name} in this image in detail.\n",
    "- Focus on its **fabric, style, patterns, and overall aesthetic**.\n",
    "- Mention the **fit** (e.g., loose, tight, relaxed), **comfort level**, and **mobility**.\n",
    "- Describe the **material and texture** (e.g., soft cotton, thick wool, waterproof fabric).\n",
    "- Indicate whether it is **suitable for certain weather conditions** (e.g., breathable for summer, ideal for rainy days).\n",
    "- Suggest occasions it is best suited for (e.g., casual, formal, date night, outdoor wear, business attire).\n",
    "- Optionally mention what it might **pair well with** (e.g., jeans, sneakers, high heels, trench coat).\n",
    "- Ignore other clothing items in the image and focus only on the {color} {name}.\n",
    "- Do NOT add any extra information outside the description.\n",
    "- Write the response as a **single paragraph** with **natural, flowing sentences**.\n",
    "\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    command = f'{LLAVA_CLI_PATH} -m {LLAVA_MODEL_PATH} --mmproj {MM_PROJ_PATH} --image {shlex.quote(image_path)} -c 4096 -p \"{prompt}\" > {output_file}'\n",
    "    print(f\"Running Command: {command}\")  # Debugging\n",
    "    \n",
    "    process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    print(\"STDOUT:\", process.stdout)  # Debugging\n",
    "    print(\"STDERR:\", process.stderr)  # Debugging\n",
    "    \n",
    "    # Extract clean description\n",
    "    description = extract_description(output_file)\n",
    "\n",
    "    # Save the description to a file\n",
    "    with open(description_path, \"w\") as desc_file:\n",
    "        desc_file.write(description)\n",
    "        \n",
    "    print(f\"Generated Description for {name}: {description}\")\n",
    "    return description\n",
    "\n",
    "# Apply LLaVA on limited products\n",
    "df['description'] = df.apply(lambda row: generate_description(row['image link'], row['name'], row['color']), axis=1)\n",
    "df['image_path'] = df.apply(lambda row: os.path.join(IMAGES_DATA, f\"{row['name'].replace(' ', '_')}.jpg\"), axis=1)\n",
    "\n",
    "print(\"Descriptions generated and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: (takes time)\n",
    "- Generate embedding with MiniLM-L6-v2\n",
    "- Convert embeddings into FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS index...\n",
      "No new products found. Using existing FAISS index.\n",
      "FAISS index ready & embeddings stored in df!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Directory for FAISS index\n",
    "FAISS_DIR = \"faiss_data\"\n",
    "os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "\n",
    "# File path for FAISS index\n",
    "FAISS_INDEX_FILE = os.path.join(FAISS_DIR, \"faiss_index.bin\")\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 1: Load FAISS index if it exists\n",
    "if os.path.exists(FAISS_INDEX_FILE):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(FAISS_INDEX_FILE)\n",
    "    num_existing = index.ntotal  # Number of stored products in FAISS\n",
    "\n",
    "    # Retrieve stored embeddings only if FAISS has indexed products\n",
    "    if num_existing > 0:\n",
    "        existing_embeddings = np.zeros((num_existing, index.d), dtype=np.float32)\n",
    "        index.reconstruct_batch(np.arange(num_existing), existing_embeddings)  # Batch retrieval\n",
    "\n",
    "        # Assign stored embeddings back to df\n",
    "        df.loc[df.index[:num_existing], \"embedding\"] = pd.Series(list(existing_embeddings))\n",
    "\n",
    "    # Identify new products that don't have an index yet\n",
    "    new_products = df[df[\"embedding\"].isna()]\n",
    "\n",
    "else:\n",
    "    print(\"Creating new FAISS index...\")\n",
    "    index = None  # Placeholder for FAISS index\n",
    "    new_products = df  # All products are new\n",
    "\n",
    "# Step 2: Generate embeddings ONLY for new products\n",
    "if not new_products.empty:\n",
    "    print(f\"Found {len(new_products)} new products. Updating FAISS index...\")\n",
    "\n",
    "    # ðŸš€ **Batch Encode New Descriptions**\n",
    "    new_embeddings = embedding_model.encode(\n",
    "        new_products[\"description\"].tolist(),\n",
    "        batch_size=32,\n",
    "        convert_to_numpy=True\n",
    "    ).astype(np.float32)  # Ensure correct dtype\n",
    "\n",
    "    new_embeddings = np.array(new_embeddings, dtype=np.float32)\n",
    "\n",
    "    # Store embeddings in df using `.loc`\n",
    "    df.loc[new_products.index, \"embedding\"] = pd.Series(list(new_embeddings), index=new_products.index)\n",
    "\n",
    "\n",
    "    # Convert to FAISS format\n",
    "    new_embeddings_array = np.vstack(df.loc[new_products.index, \"embedding\"].to_numpy())\n",
    "\n",
    "    new_embeddings_array = np.array(new_embeddings_array, dtype=np.float32)\n",
    "\n",
    "    # Add new embeddings to FAISS\n",
    "    if index is None:\n",
    "        index = faiss.IndexFlatL2(new_embeddings_array.shape[1])  # Create FAISS index\n",
    "    index.add(new_embeddings_array)\n",
    "\n",
    "    # Save updated FAISS index\n",
    "    faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "    print(\"FAISS index updated with new products!\")\n",
    "\n",
    "else:\n",
    "    print(\"No new products found. Using existing FAISS index.\")\n",
    "\n",
    "print(\"FAISS index ready & embeddings stored in df!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:\n",
    "- Retrieve top 3 products with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def retrieve_relevant_products(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: Combines FAISS (dense) and TF-IDF (sparse) for better search.\n",
    "    \"\"\"\n",
    "    #Convert query to FAISS embedding\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True).reshape(1, -1)\n",
    "\n",
    "    #Retrieve from FAISS\n",
    "    top_k_faiss = top_k * 3  # Retrieve more to rerank better\n",
    "    distances, indices = index.search(query_embedding.astype(np.float32), top_k_faiss)\n",
    "    retrieved_products = df.iloc[indices[0]].copy()  # Use .copy() to avoid modifying original df\n",
    "\n",
    "    #Compute cosine similarity for reranking\n",
    "    product_embeddings = np.vstack(retrieved_products[\"embedding\"].to_numpy())\n",
    "    similarity_scores = cosine_similarity(query_embedding, product_embeddings)[0]\n",
    "    retrieved_products[\"similarity\"] = similarity_scores\n",
    "\n",
    "    #Sparse Retrieval Using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"name\"] + \" \" + df[\"description\"])  # Use both name & description\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    #Compute TF-IDF similarity scores for retrieved products only\n",
    "    sparse_scores = np.array((tfidf_matrix[retrieved_products.index] @ query_vector.T).todense()).flatten()\n",
    "\n",
    "    #Assign sparse scores only to retrieved products\n",
    "    retrieved_products[\"sparse_score\"] = sparse_scores\n",
    "\n",
    "    # Normalize scores and rerank\n",
    "    retrieved_products[\"final_score\"] = (\n",
    "        0.7 * retrieved_products[\"similarity\"] +  # Dense search weight\n",
    "        0.3 * retrieved_products[\"sparse_score\"]  # Sparse search weight\n",
    "    )\n",
    "    retrieved_products = retrieved_products.sort_values(\"final_score\", ascending=False)\n",
    "\n",
    "    return retrieved_products.head(top_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:\n",
    "- Generate rag text response\n",
    "- Pass in result details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "# import ollama \n",
    "\n",
    "# def generate_rag_response(user_query):\n",
    "#     \"\"\"\n",
    "#     Uses Ollama to generate structured product recommendations with explanations, styling tips, and alternative suggestions.\n",
    "#     \"\"\"\n",
    "#     retrieved_products = retrieve_relevant_products(user_query, top_k=3)\n",
    "\n",
    "#     if retrieved_products.empty:\n",
    "#         return []\n",
    "\n",
    "#     #Create a formatted product list for AI to process\n",
    "#     product_list = \"\\n\\n\".join(\n",
    "#         [\n",
    "#             f\"*Name:* {row['name']}\\n\"\n",
    "#             f\"*Description:* {row['description']}\\n\"\n",
    "#             for i, row in retrieved_products.iterrows()\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     #Construct the AI prompt\n",
    "#     prompt = f\"\"\"\n",
    "# User Query: \"{user_query}\"\n",
    "\n",
    "# The following fashion products were retrieved as the most relevant matches:\n",
    "\n",
    "# {product_list}\n",
    "\n",
    "# Act as a fashion AI assistant. For each product, explain why it was chosen, how it matches the user's request, and provide styling tips.\n",
    "# Respond with a brief and short structured paragraph for each product.\n",
    "# Don't display the name of the product in your response.\n",
    "# Just give your explanations as instructed.\n",
    "# \"\"\"\n",
    "\n",
    "#     #Generate response with Ollama\n",
    "#     response = ollama.chat(\n",
    "#         model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "#     print(response)\n",
    "#     response_text = response[\"message\"][\"content\"]\n",
    "\n",
    "#     #Split the AI response into separate product explanations\n",
    "#     explanations = response_text.split(\"\\n\\n\")  # Splitting paragraphs for individual products\n",
    "    \n",
    "#     #Format structured output for the chat\n",
    "#     structured_recommendations = []\n",
    "#     for (index, row), explanation in zip(retrieved_products.iterrows(), explanations):\n",
    "#         structured_recommendations.append(\n",
    "#             {\n",
    "#                 \"text\": f\"**{row['name']}**\\n\\n**${row['price']}**\\n\\n{explanation[3:]}\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "#                 \"image\": row[\"image link\"],\n",
    "#                 \"images\": row[\"images\"]\n",
    "#             }\n",
    "#         )\n",
    "\n",
    "#     return structured_recommendations  # Return structured list of text + images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 5\n",
    "# '''\n",
    "\n",
    "# import gradio as gr\n",
    "# import ollama \n",
    "\n",
    "# def generate_rag_response(user_query, criteria=None, session=None):\n",
    "#     \"\"\"\n",
    "#     Uses Ollama to generate structured product recommendations with explanations.\n",
    "    \n",
    "#     Args:\n",
    "#         user_query (str): The user's search query\n",
    "#         criteria (dict, optional): Dictionary of collected criteria. Defaults to None.\n",
    "#         session (dict, optional): The user's session data for additional context. Defaults to None.\n",
    "    \n",
    "#     Returns:\n",
    "#         list: List of structured recommendation objects with text, images, etc.\n",
    "#     \"\"\"\n",
    "#     # Prepare the search query with all available criteria\n",
    "#     if criteria:\n",
    "#         criteria_terms = [value for key, value in criteria.items() if value and key != \"other\"]\n",
    "#         if criteria_terms:\n",
    "#             enhanced_query = f\"{' '.join(criteria_terms)} {user_query}\"\n",
    "#         else:\n",
    "#             enhanced_query = user_query\n",
    "#     else:\n",
    "#         enhanced_query = user_query\n",
    "        \n",
    "#     print(f\"Searching for: {enhanced_query}\")\n",
    "    \n",
    "#     # Get relevant products\n",
    "#     retrieved_products = retrieve_relevant_products(enhanced_query, top_k=3)\n",
    "\n",
    "#     if retrieved_products.empty:\n",
    "#         return []\n",
    "\n",
    "#     # Create a formatted product list for AI to process\n",
    "#     product_list = \"\\n\\n\".join(\n",
    "#         [\n",
    "#             f\"*Name:* {row['name']}\\n\"\n",
    "#             f\"*Description:* {row['description']}\\n\"\n",
    "#             f\"*Price:* ${row['price']}\\n\"\n",
    "#             f\"*Color:* {row['color']}\\n\"\n",
    "#             for i, row in retrieved_products.iterrows()\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # Create conversation context to help with personalization\n",
    "#     conversation_context = \"\"\n",
    "#     if session and \"conversation_history\" in session:\n",
    "#         # Get the last 3 user messages for context\n",
    "#         user_messages = [msg[\"content\"] for msg in session[\"conversation_history\"] \n",
    "#                         if msg[\"role\"] == \"user\"][-3:]\n",
    "#         if user_messages:\n",
    "#             conversation_context = \"Recent conversation:\\n\" + \"\\n\".join(user_messages)\n",
    "\n",
    "#     # Construct the AI prompt with enhanced context\n",
    "#     prompt = f\"\"\"\n",
    "# User Query: \"{user_query}\"\n",
    "# User Preferences: {criteria if criteria else 'Not specified'}\n",
    "# {conversation_context}\n",
    "\n",
    "# The following fashion products were retrieved as the most relevant matches:\n",
    "\n",
    "# {product_list}\n",
    "\n",
    "# Act as a fashion AI assistant. For each product:\n",
    "# 1. Explain why it matches the user's preferences and query\n",
    "# 2. Highlight key features that make it suitable for their needs\n",
    "# 3. Provide 1-2 brief styling tips or suggestions\n",
    "# 4. If appropriate, mention occasions where this would work well\n",
    "\n",
    "# Be conversational and personalized. Respond with a brief paragraph (3-5 sentences max) for each product.\n",
    "# Don't start with phrases like \"This product...\" or \"Here we have...\".\n",
    "# Don't repeat the product name verbatim.\n",
    "# \"\"\"\n",
    "\n",
    "#     # Generate response with Ollama\n",
    "#     try:\n",
    "#         response = ollama.chat(\n",
    "#             model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "#         response_text = response[\"message\"][\"content\"]\n",
    "\n",
    "#         # Split the AI response into separate product explanations\n",
    "#         explanations = response_text.split(\"\\n\\n\")  # Splitting paragraphs for individual products\n",
    "        \n",
    "#         # Format structured output for the chat\n",
    "#         structured_recommendations = []\n",
    "#         for (index, row), explanation in zip(retrieved_products.iterrows(), explanations[:len(retrieved_products)]):\n",
    "#             # Clean up the explanation - remove product name if it appears at the start\n",
    "#             clean_explanation = explanation.strip()\n",
    "#             product_name_lower = row['name'].lower()\n",
    "            \n",
    "#             # If explanation starts with the product name, remove it\n",
    "#             if clean_explanation.lower().startswith(product_name_lower[:20]):\n",
    "#                 clean_explanation = clean_explanation[len(product_name_lower):].strip()\n",
    "            \n",
    "#             # Format the product card with emoji for visual appeal\n",
    "#             structured_recommendations.append(\n",
    "#                 {\n",
    "#                     \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{clean_explanation}\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "#                     \"image\": row[\"image link\"],\n",
    "#                     \"images\": row[\"images\"]\n",
    "#                 }\n",
    "#             )\n",
    "\n",
    "#         return structured_recommendations  # Return structured list of text + images\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error generating recommendations: {e}\")\n",
    "#         # Fallback without Ollama explanations\n",
    "#         structured_recommendations = []\n",
    "#         for index, row in retrieved_products.iterrows():\n",
    "#             structured_recommendations.append(\n",
    "#                 {\n",
    "#                     \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{row['description'][:150]}...\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "#                     \"image\": row[\"image link\"],\n",
    "#                     \"images\": row[\"images\"]\n",
    "#                 }\n",
    "#             )\n",
    "#         return structured_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for the \"sequence item 1: expected str instance, list found\" error\n",
    "# Add this to the chat_fashion_assistant function\n",
    "\n",
    "def generate_rag_response(user_query, criteria=None, session=None):\n",
    "    \"\"\"\n",
    "    Uses Ollama to generate structured product recommendations with explanations.\n",
    "    Fixed to handle list values properly.\n",
    "    \"\"\"\n",
    "    # Prepare the search query with all available criteria\n",
    "    if criteria:\n",
    "        # FIX: Convert any non-string criteria values to strings before joining\n",
    "        criteria_terms = []\n",
    "        for key, value in criteria.items():\n",
    "            if key != \"other\" and value is not None:\n",
    "                # Handle different value types\n",
    "                if isinstance(value, str):\n",
    "                    criteria_terms.append(value)\n",
    "                elif isinstance(value, list):\n",
    "                    # Convert list to string by joining\n",
    "                    criteria_terms.append(\" \".join(str(item) for item in value))\n",
    "                elif isinstance(value, dict):\n",
    "                    # Extract values from dict\n",
    "                    criteria_terms.append(\" \".join(str(item) for item in value.values() if item))\n",
    "                else:\n",
    "                    # Convert other types to string\n",
    "                    criteria_terms.append(str(value))\n",
    "                    \n",
    "        if criteria_terms:\n",
    "            enhanced_query = f\"{' '.join(criteria_terms)} {user_query}\"\n",
    "        else:\n",
    "            enhanced_query = user_query\n",
    "    else:\n",
    "        enhanced_query = user_query\n",
    "        \n",
    "    print(f\"Searching for: {enhanced_query}\")\n",
    "    \n",
    "    # Get relevant products\n",
    "    retrieved_products = retrieve_relevant_products(enhanced_query, top_k=3)\n",
    "\n",
    "    if retrieved_products.empty:\n",
    "        return []\n",
    "\n",
    "    # Create a formatted product list for AI to process\n",
    "    product_list = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"*Name:* {row['name']}\\n\"\n",
    "            f\"*Description:* {row['description']}\\n\"\n",
    "            f\"*Price:* ${row['price']}\\n\"\n",
    "            f\"*Color:* {row['color']}\\n\"\n",
    "            for i, row in retrieved_products.iterrows()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create conversation context to help with personalization\n",
    "    conversation_context = \"\"\n",
    "    if session and \"conversation_history\" in session:\n",
    "        # Get the last 3 user messages for context\n",
    "        user_messages = [msg[\"content\"] for msg in session[\"conversation_history\"] \n",
    "                        if msg[\"role\"] == \"user\"][-3:]\n",
    "        if user_messages:\n",
    "            conversation_context = \"Recent conversation:\\n\" + \"\\n\".join(user_messages)\n",
    "\n",
    "    # Construct the AI prompt with enhanced context\n",
    "    prompt = f\"\"\"\n",
    "User Query: \"{user_query}\"\n",
    "User Preferences: {str(criteria) if criteria else 'Not specified'}\n",
    "{conversation_context}\n",
    "\n",
    "The following fashion products were retrieved as the most relevant matches:\n",
    "\n",
    "{product_list}\n",
    "\n",
    "Act as a fashion AI assistant. For each product:\n",
    "1. Explain why it matches the user's preferences and query\n",
    "2. Highlight key features that make it suitable for their needs\n",
    "3. Provide 1-2 brief styling tips or suggestions\n",
    "4. If appropriate, mention occasions where this would work well\n",
    "\n",
    "Be conversational and personalized. Respond with a brief paragraph (3-5 sentences max) for each product.\n",
    "Don't start with phrases like \"This product...\" or \"Here we have...\".\n",
    "Don't repeat the product name verbatim.\n",
    "\"\"\"\n",
    "\n",
    "    # Generate response with Ollama\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        response_text = response[\"message\"][\"content\"]\n",
    "\n",
    "        # Split the AI response into separate product explanations\n",
    "        explanations = response_text.split(\"\\n\\n\")  # Splitting paragraphs for individual products\n",
    "        \n",
    "        # Format structured output for the chat\n",
    "        structured_recommendations = []\n",
    "        for (index, row), explanation in zip(retrieved_products.iterrows(), explanations[:len(retrieved_products)]):\n",
    "            # Clean up the explanation - remove product name if it appears at the start\n",
    "            clean_explanation = explanation.strip()\n",
    "            product_name_lower = str(row['name']).lower()\n",
    "            \n",
    "            # If explanation starts with the product name, remove it\n",
    "            if clean_explanation.lower().startswith(product_name_lower[:20]):\n",
    "                clean_explanation = clean_explanation[len(product_name_lower):].strip()\n",
    "            \n",
    "            # Format the product card with emoji for visual appeal\n",
    "            structured_recommendations.append(\n",
    "                {\n",
    "                    \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{clean_explanation}\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "                    \"image\": row[\"image link\"],\n",
    "                    \"images\": row[\"images\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return structured_recommendations  # Return structured list of text + images\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating recommendations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Fallback without Ollama explanations\n",
    "        structured_recommendations = []\n",
    "        for index, row in retrieved_products.iterrows():\n",
    "            structured_recommendations.append(\n",
    "                {\n",
    "                    \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{row['description'][:150]}...\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "                    \"image\": row[\"image link\"],\n",
    "                    \"images\": row[\"images\"]\n",
    "                }\n",
    "            )\n",
    "        return structured_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: \n",
    "- Chat function for Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# def chat_fashion_assistant(user_input, history):\n",
    "#     \"\"\"\n",
    "#     Processes user query and returns structured product recommendations with AI-generated explanations.\n",
    "#     \"\"\"\n",
    "#     #Get AI-generated recommendations\n",
    "#     recommendations = generate_rag_response(user_input)\n",
    "\n",
    "#     if not recommendations:\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"No matching products found.\"}]\n",
    "\n",
    "#     #Create structured response list\n",
    "#     response_list = []\n",
    "#     for rec in recommendations:\n",
    "#         images = ast.literal_eval(rec[\"images\"])\n",
    "        \n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # AI explanation\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "#                                                                         columns=4, \n",
    "#                                                                         rows=1, \n",
    "#                                                                         object_fit=\"cover\", \n",
    "#                                                                         height=\"automatic\",\n",
    "#                                                                         allow_preview=True)\n",
    "#                                                                         }) \n",
    "\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds a horizontal divider and spacing\n",
    "\n",
    "#         # response_list.append(gr.Image(rec[\"image\"]))  # Product image\n",
    "\n",
    "#     return response_list  #Returning structured chat messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 6\n",
    "# '''\n",
    "\n",
    "# import ast\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Track conversation state\n",
    "# user_sessions = defaultdict(lambda: {\n",
    "#     \"conversation_history\": [],\n",
    "#     \"criteria_collected\": {},\n",
    "#     \"stage\": \"initial\",\n",
    "#     \"recommendations_shown\": False\n",
    "# })\n",
    "\n",
    "# def chat_fashion_assistant(user_input, history, session_id=\"default\"):\n",
    "#     \"\"\"\n",
    "#     AI-powered conversational shopping assistant that maintains conversation state\n",
    "#     and provides personalized product recommendations.\n",
    "    \n",
    "#     Args:\n",
    "#         user_input (str): The user's message\n",
    "#         history (list): The chat history\n",
    "#         session_id (str, optional): Unique identifier for the user session. Defaults to \"default\".\n",
    "    \n",
    "#     Returns:\n",
    "#         list: List of response messages with text and visual content\n",
    "#     \"\"\"\n",
    "#     # Get or create session\n",
    "#     session = user_sessions[session_id]\n",
    "    \n",
    "#     # Special case for conversation restart\n",
    "#     restart_phrases = [\"start over\", \"restart\", \"reset\", \"new search\", \"start again\"]\n",
    "#     if any(phrase in user_input.lower() for phrase in restart_phrases):\n",
    "#         # Reset the session\n",
    "#         session[\"criteria_collected\"] = {}\n",
    "#         session[\"stage\"] = \"initial\"\n",
    "#         session[\"recommendations_shown\"] = False\n",
    "#         session[\"conversation_history\"] = []\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today?\"}]\n",
    "    \n",
    "#     # Add user message to conversation history\n",
    "#     session[\"conversation_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "#     # Have AI analyze the message and context\n",
    "#     try:\n",
    "#         # Create a context-aware prompt for the AI\n",
    "#         prompt = f\"\"\"\n",
    "# You are a fashion shopping assistant helping a customer find products. Analyze their latest message and previous conversation to:\n",
    "\n",
    "# 1. Extract shopping criteria (if any)\n",
    "# 2. Determine what the conversation needs next\n",
    "# 3. Format your response as JSON\n",
    "\n",
    "# Previous conversation:\n",
    "# {json.dumps(session[\"conversation_history\"][:-1])[:1000] if len(session[\"conversation_history\"]) > 1 else \"This is the start of the conversation.\"}\n",
    "\n",
    "# Current criteria collected:\n",
    "# {json.dumps(session[\"criteria_collected\"])}\n",
    "\n",
    "# Current stage: {session[\"stage\"]}\n",
    "# Recommendations shown: {\"Yes\" if session[\"recommendations_shown\"] else \"No\"}\n",
    "\n",
    "# Latest user message: \"{user_input}\"\n",
    "\n",
    "# Respond with JSON only, in this format:\n",
    "# {{\n",
    "#   \"extracted_criteria\": {{\n",
    "#     \"item_type\": \"detected item or null\",\n",
    "#     \"style\": \"detected style or null\",\n",
    "#     \"color\": \"detected color or null\", \n",
    "#     \"occasion\": \"detected occasion or null\",\n",
    "#     \"price_range\": \"detected price range or null\",\n",
    "#     \"other\": \"any other important criteria detected\"\n",
    "#   }},\n",
    "#   \"action\": \"one of: greet, ask_for_criteria, search_products, show_more, restart, answer_question\",\n",
    "#   \"missing_criterion\": \"most important missing criterion to ask about or null\",\n",
    "#   \"question\": \"follow-up question to ask (if applicable) or null\",\n",
    "#   \"understanding\": \"brief summary of what you understand about their needs\",\n",
    "#   \"ready_to_search\": true/false,\n",
    "#   \"search_query\": \"optimized search query based on all criteria and context\"\n",
    "# }}\n",
    "\n",
    "# Important: \n",
    "# - The extracted_criteria should ONLY include values you're confident about from the current message or previous context\n",
    "# - Do NOT invent criteria not mentioned by the user\n",
    "# - For action, use \"search_products\" only when you have enough criteria OR the user is clearly asking to see products\n",
    "# - For search_query, optimize the terms for product search (remove filler words, focus on key features)\n",
    "# \"\"\"\n",
    "\n",
    "#         # Send to Ollama for analysis\n",
    "#         response = ollama.chat(\n",
    "#             model=\"mistral\", \n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "        \n",
    "#         # Parse the JSON response\n",
    "#         analysis_text = response[\"message\"][\"content\"]\n",
    "#         # Find the JSON part in case there's additional text\n",
    "#         json_start = analysis_text.find('{')\n",
    "#         json_end = analysis_text.rfind('}') + 1\n",
    "        \n",
    "#         if json_start >= 0 and json_end > json_start:\n",
    "#             json_part = analysis_text[json_start:json_end]\n",
    "#             analysis = json.loads(json_part)\n",
    "#         else:\n",
    "#             # Fallback if JSON parsing fails\n",
    "#             raise ValueError(\"Could not extract valid JSON from the response\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error analyzing message: {e}\")\n",
    "#         # Fallback analysis if there's an error\n",
    "#         analysis = {\n",
    "#             \"extracted_criteria\": {},\n",
    "#             \"action\": \"search_products\" if \"show me\" in user_input.lower() else \"ask_for_criteria\",\n",
    "#             \"missing_criterion\": \"item_type\",\n",
    "#             \"question\": \"What type of clothing are you looking for?\",\n",
    "#             \"understanding\": \"I'm trying to understand what you're looking for.\",\n",
    "#             \"ready_to_search\": False,\n",
    "#             \"search_query\": user_input\n",
    "#         }\n",
    "    \n",
    "#     # Update session with extracted criteria\n",
    "#     for criterion, value in analysis[\"extracted_criteria\"].items():\n",
    "#         if value and value.lower() not in (\"null\", \"none\"):\n",
    "#             session[\"criteria_collected\"][criterion] = value\n",
    "    \n",
    "#     # Handle different conversation actions\n",
    "#     if analysis[\"action\"] == \"greet\":\n",
    "#         session[\"stage\"] = \"collecting\"\n",
    "#         return [{\"role\": \"assistant\", \"content\": f\"Hi! I'd be happy to help you find the perfect outfit. {analysis.get('question', 'What type of clothing are you looking for today?')}\"}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"ask_for_criteria\":\n",
    "#         session[\"stage\"] = \"collecting\"\n",
    "#         question = analysis.get(\"question\") or f\"Can you tell me what kind of {analysis.get('missing_criterion', 'item')} you're looking for?\"\n",
    "#         return [{\"role\": \"assistant\", \"content\": question}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"search_products\" or analysis[\"action\"] == \"show_more\":\n",
    "#         session[\"stage\"] = \"searching\"\n",
    "#         # Use the existing retrieve_relevant_products and generate_rag_response functions\n",
    "#         search_query = analysis.get(\"search_query\") or user_input\n",
    "        \n",
    "#         # Get AI-generated recommendations\n",
    "#         recommendations = generate_rag_response(search_query, session[\"criteria_collected\"], session)\n",
    "        \n",
    "#         if not recommendations:\n",
    "#             # No products found - ask if user wants to broaden search\n",
    "#             session[\"recommendations_shown\"] = True\n",
    "#             return [{\"role\": \"assistant\", \"content\": \"I couldn't find any products matching your criteria. Could you be more general or try different options?\"}]\n",
    "        \n",
    "#         # Create structured response list\n",
    "#         response_list = []\n",
    "        \n",
    "#         # First, summarize what we understood from their requirements\n",
    "#         criteria_display = {\n",
    "#             \"item_type\": \"Item\", \n",
    "#             \"style\": \"Style\", \n",
    "#             \"color\": \"Color\", \n",
    "#             \"occasion\": \"Occasion\", \n",
    "#             \"price_range\": \"Price\",\n",
    "#             \"other\": \"Other\"\n",
    "#         }\n",
    "        \n",
    "#         criteria_summary = \", \".join([f\"{criteria_display[k]}: {v}\" for k, v in session[\"criteria_collected\"].items() \n",
    "#                                       if v and k in criteria_display])\n",
    "        \n",
    "#         if criteria_summary:\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": f\"Here are some recommendations based on your preferences ({criteria_summary}):\"})\n",
    "#         else:\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": \"Here are some recommendations based on your request:\"})\n",
    "        \n",
    "#         # Add products with images and descriptions\n",
    "#         for rec in recommendations:\n",
    "#             try:\n",
    "#                 images = ast.literal_eval(rec[\"images\"])\n",
    "#             except:\n",
    "#                 # Fallback if images can't be parsed\n",
    "#                 images = [rec[\"image\"]]\n",
    "            \n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # Product with AI explanation\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "#                                                                           columns=4, \n",
    "#                                                                           rows=1, \n",
    "#                                                                           object_fit=\"cover\", \n",
    "#                                                                           height=\"automatic\",\n",
    "#                                                                           allow_preview=True)\n",
    "#                                                                          }) \n",
    "    \n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds spacing\n",
    "    \n",
    "#         # Add follow-up prompt\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": \"Would you like to see more options, or should I help you find something else?\"})\n",
    "        \n",
    "#         # Update session\n",
    "#         session[\"recommendations_shown\"] = True\n",
    "#         session[\"stage\"] = \"recommending\"\n",
    "        \n",
    "#         # Add assistant response to conversation history\n",
    "#         session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": \"I showed some product recommendations based on the user's criteria.\"})\n",
    "        \n",
    "#         return response_list\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"restart\":\n",
    "#         # Reset the session (redundant with the check at the beginning, but keeping for completeness)\n",
    "#         session[\"criteria_collected\"] = {}\n",
    "#         session[\"stage\"] = \"collecting\" \n",
    "#         session[\"recommendations_shown\"] = False\n",
    "#         session[\"conversation_history\"] = []\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today?\"}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"answer_question\":\n",
    "#         # If the AI detects a question not related to product search\n",
    "#         if \"question\" in analysis and analysis[\"question\"]:\n",
    "#             return [{\"role\": \"assistant\", \"content\": analysis[\"question\"]}]\n",
    "#         else:\n",
    "#             return [{\"role\": \"assistant\", \"content\": \"I'm here to help you find fashion products. What kind of item are you looking for?\"}]\n",
    "    \n",
    "#     # Default fallback response if analysis doesn't yield actionable results\n",
    "#     return [{\"role\": \"assistant\", \"content\": \"I'm not sure I understood. Could you tell me what kind of clothing or fashion item you're looking for?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_with_llava(image_path, user_query=None):\n",
    "    \"\"\"\n",
    "    Uses LLaVA to generate a description of the clothing item in the image,\n",
    "    focusing on specific items mentioned in the user's query.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the uploaded image\n",
    "        user_query (str, optional): The user's text query to focus the analysis\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (description, keywords) - The focused description and extracted keywords\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import shlex\n",
    "    import re\n",
    "    import tempfile\n",
    "    \n",
    "    print(f\"[DEBUG] Starting image analysis for: {image_path}\")\n",
    "    if user_query:\n",
    "        print(f\"[DEBUG] Query-aware analysis with: '{user_query}'\")\n",
    "    \n",
    "    # Extract specific item mention from the query\n",
    "    target_item = None\n",
    "    if user_query:\n",
    "        # Common clothing items to look for in the query\n",
    "        clothing_items = [\n",
    "            \"jacket\", \"coat\", \"dress\", \"shirt\", \"pants\", \"jeans\", \"sweater\", \n",
    "            \"hoodie\", \"skirt\", \"blazer\", \"suit\", \"top\", \"shorts\", \"blouse\", \n",
    "            \"t-shirt\", \"tee\", \"shoes\", \"boots\", \"sneakers\", \"hat\", \"scarf\",\n",
    "            \"bag\", \"purse\", \"backpack\", \"accessory\", \"jewelry\", \"watch\",\n",
    "            \"glasses\", \"sunglasses\", \"outfit\", \"look\", \"style\", \"fashion\"\n",
    "        ]\n",
    "        \n",
    "        # Extract the specific item the user is interested in\n",
    "        for item in clothing_items:\n",
    "            if item in user_query.lower():\n",
    "                target_item = item\n",
    "                print(f\"[DEBUG] Detected target item in query: '{target_item}'\")\n",
    "                break\n",
    "    \n",
    "    # Use the exact same LLaVA paths as in Step 2\n",
    "    LLAVA_CLI_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/llama-llava-cli\"\n",
    "    LLAVA_MODEL_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llava-v1.6-mistral-7b/Mistral-7B-Instruct-v0.2-F32-Q4_K_M.gguf\"\n",
    "    MM_PROJ_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/vit/mmproj-model-f16.gguf\"\n",
    "    \n",
    "    # Temporary file for LLaVA output\n",
    "    output_file = os.path.join(tempfile.gettempdir(), \"llava_output.txt\")\n",
    "    print(f\"[DEBUG] LLaVA output will be saved to: {output_file}\")\n",
    "    \n",
    "    # Craft a more focused prompt based on the user's query\n",
    "    if target_item:\n",
    "        # Focus on the specific item the user mentioned\n",
    "        prompt = f\"\"\"\n",
    "USER:\n",
    "Describe only the {target_item} in this image in detail. Focus on:\n",
    "- Style, design, and unique features of the {target_item}\n",
    "- Color and pattern details \n",
    "- Material and texture appearance\n",
    "- Fit and silhouette\n",
    "- Any distinctive elements or embellishments\n",
    "\n",
    "Ignore other clothing items or accessories unless they're part of the {target_item}.\n",
    "Then provide a list of 5-7 keywords that best describe this {target_item}, prefixed with \"KEYWORDS:\".\n",
    "\n",
    "A:\n",
    "\"\"\"\n",
    "    else:\n",
    "        # Generic clothing description if no specific item was mentioned\n",
    "        prompt = f\"\"\"\n",
    "USER:\n",
    "Describe the most prominent clothing item in this image in detail. Focus on:\n",
    "- Identify the main garment (e.g., jacket, dress, pants)\n",
    "- Style, design, and unique features\n",
    "- Color and pattern details\n",
    "- Material and texture appearance\n",
    "- Fit and silhouette\n",
    "- Any distinctive elements or embellishments\n",
    "\n",
    "Then provide a list of 5-7 keywords that best describe this item, prefixed with \"KEYWORDS:\".\n",
    "\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "    # Run LLaVA command\n",
    "    try:\n",
    "        command = f'{LLAVA_CLI_PATH} -m {LLAVA_MODEL_PATH} --mmproj {MM_PROJ_PATH} --image {shlex.quote(image_path)} -c 4096 -p \"{prompt}\" > {output_file}'\n",
    "        print(f\"[DEBUG] Executing LLaVA command\")\n",
    "        \n",
    "        process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        \n",
    "        # Check if the command succeeded\n",
    "        if process.returncode != 0:\n",
    "            print(f\"[ERROR] LLaVA command failed with return code {process.returncode}\")\n",
    "            print(f\"[ERROR] stderr: {process.stderr}\")\n",
    "            return f\"A clothing item\" + (f\" (possibly a {target_item})\" if target_item else \"\"), [\"clothing\"]\n",
    "        \n",
    "        print(f\"[DEBUG] LLaVA command completed successfully\")\n",
    "        \n",
    "        # Read the output file\n",
    "        with open(output_file, 'r') as f:\n",
    "            output_text = f.read()\n",
    "            \n",
    "        print(f\"[DEBUG] LLaVA output file size: {len(output_text)} characters\")\n",
    "        \n",
    "        # Extract the description part\n",
    "        description_lines = []\n",
    "        capture = False\n",
    "        \n",
    "        for line in output_text.split('\\n'):\n",
    "            if 'encode_image_with_clip: image encoded' in line:\n",
    "                capture = True\n",
    "                print(f\"[DEBUG] Found marker line for description start\")\n",
    "                continue\n",
    "            \n",
    "            if capture and not line.startswith('['):\n",
    "                description_lines.append(line)\n",
    "        \n",
    "        description = ' '.join(description_lines).strip()\n",
    "        print(f\"[DEBUG] Extracted description ({len(description)} chars): {description[:100]}...\")\n",
    "        \n",
    "        # Extract keywords from the description\n",
    "        keywords = []\n",
    "        if \"KEYWORDS:\" in description:\n",
    "            print(f\"[DEBUG] Found KEYWORDS section in output\")\n",
    "            # Get the part after \"KEYWORDS:\"\n",
    "            keyword_section = description.split(\"KEYWORDS:\")[1].strip()\n",
    "            # Split by commas or spaces if no commas\n",
    "            if \",\" in keyword_section:\n",
    "                keywords = [k.strip().lower() for k in keyword_section.split(\",\")]\n",
    "            else:\n",
    "                keywords = re.findall(r'\\b[A-Za-z]+\\b', keyword_section.lower())\n",
    "            \n",
    "            # Clean up the description to remove the keywords section\n",
    "            description = description.split(\"KEYWORDS:\")[0].strip()\n",
    "            print(f\"[DEBUG] Successfully extracted {len(keywords)} keywords: {keywords}\")\n",
    "            \n",
    "            # Add the target item to keywords if it's not already there\n",
    "            if target_item and target_item not in keywords:\n",
    "                keywords.insert(0, target_item)\n",
    "        else:\n",
    "            print(f\"[DEBUG] No KEYWORDS section found, extracting from description\")\n",
    "            # If no keywords section, extract important words from description\n",
    "            clothing_terms = [\"dress\", \"jacket\", \"shirt\", \"pants\", \"coat\", \"blouse\", \"sweater\", \n",
    "                             \"jeans\", \"skirt\", \"hoodie\", \"blazer\", \"suit\", \"top\", \"shorts\"]\n",
    "            color_terms = [\"black\", \"white\", \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \n",
    "                          \"pink\", \"orange\", \"grey\", \"gray\", \"brown\", \"navy\", \"beige\"]\n",
    "            style_terms = [\"casual\", \"formal\", \"elegant\", \"vintage\", \"modern\", \"classic\", \n",
    "                          \"sporty\", \"bohemian\", \"minimalist\", \"business\", \"trendy\"]\n",
    "            \n",
    "            # Look for these terms in the description\n",
    "            words = re.findall(r'\\b[A-Za-z]+\\b', description.lower())\n",
    "            for word in words:\n",
    "                if (word in clothing_terms or word in color_terms or word in style_terms) and word not in keywords:\n",
    "                    keywords.append(word)\n",
    "            \n",
    "            # Ensure the target item is included\n",
    "            if target_item and target_item not in keywords:\n",
    "                keywords.insert(0, target_item)\n",
    "                \n",
    "            # Limit to most relevant keywords\n",
    "            keywords = keywords[:7]\n",
    "            print(f\"[DEBUG] Extracted {len(keywords)} keywords from description: {keywords}\")\n",
    "        \n",
    "        # If we couldn't extract a good description or keywords, provide a fallback\n",
    "        if not description or len(description) < 20:\n",
    "            print(f\"[DEBUG] Description too short, using fallback\")\n",
    "            return f\"A clothing item\" + (f\" (possibly a {target_item})\" if target_item else \"\"), [\"clothing\"]\n",
    "            \n",
    "        print(f\"[DEBUG] LLaVA analysis completed successfully âœ…\")\n",
    "        return description, keywords\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during image analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Provide a fallback in case of error\n",
    "        return f\"A clothing item\" + (f\" (possibly a {target_item})\" if target_item else \"\"), [\"clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track conversation state\n",
    "user_sessions = defaultdict(lambda: {\n",
    "    \"conversation_history\": [],\n",
    "    \"criteria_collected\": {},\n",
    "    \"stage\": \"initial\",\n",
    "    \"recommendations_shown\": False,\n",
    "    \"image_analysis\": None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# STEP 6: Updated Chat Fashion Assistant\n",
    "# '''\n",
    "\n",
    "# import ast\n",
    "# import json\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Track conversation state\n",
    "# user_sessions = defaultdict(lambda: {\n",
    "#     \"conversation_history\": [],\n",
    "#     \"criteria_collected\": {},\n",
    "#     \"stage\": \"initial\",\n",
    "#     \"recommendations_shown\": False,\n",
    "#     \"image_analysis\": None\n",
    "# })\n",
    "\n",
    "# def chat_fashion_assistant(user_input, image=None, history=None, session_id=\"default\"):\n",
    "#     \"\"\"\n",
    "#     AI-powered conversational shopping assistant that accepts both text and image inputs.\n",
    "    \n",
    "#     Args:\n",
    "#         user_input (str): The user's text message\n",
    "#         image (Image, optional): Uploaded image for visual search. Defaults to None.\n",
    "#         history (list, optional): Chat history. Defaults to None.\n",
    "#         session_id (str, optional): Unique session identifier. Defaults to \"default\".\n",
    "    \n",
    "#     Returns:\n",
    "#         list: List of response messages\n",
    "#     \"\"\"\n",
    "#     # Initialize history if None\n",
    "#     if history is None:\n",
    "#         history = []\n",
    "    \n",
    "#     # Get or create session\n",
    "#     session = user_sessions[session_id]\n",
    "    \n",
    "#     # Handle special restart requests\n",
    "#     restart_phrases = [\"start over\", \"restart\", \"reset\", \"new search\", \"start again\"]\n",
    "#     if user_input and any(phrase in user_input.lower() for phrase in restart_phrases):\n",
    "#         # Reset the session\n",
    "#         session[\"criteria_collected\"] = {}\n",
    "#         session[\"stage\"] = \"initial\"\n",
    "#         session[\"recommendations_shown\"] = False\n",
    "#         session[\"conversation_history\"] = []\n",
    "#         session[\"image_analysis\"] = None\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "#     # Handle image upload if present\n",
    "#     search_query = user_input if user_input else \"\"\n",
    "#     image_description = None\n",
    "    \n",
    "#     if image is not None:\n",
    "#         try:\n",
    "#             # Process the image\n",
    "#             import os\n",
    "#             import tempfile\n",
    "#             from PIL import Image as PILImage\n",
    "            \n",
    "#             print(f\"[DEBUG] Image detected in chat input\")\n",
    "            \n",
    "#             # Save the uploaded image to a temporary file\n",
    "#             temp_dir = tempfile.gettempdir()\n",
    "#             temp_img_path = os.path.join(temp_dir, f\"upload_{os.urandom(4).hex()}.jpg\")\n",
    "            \n",
    "#             # Handle different image input types\n",
    "#             if isinstance(image, str):  # Path to image\n",
    "#                 image_path = image\n",
    "#                 print(f\"[DEBUG] Image is a file path: {image_path}\")\n",
    "#             elif hasattr(image, 'save'):  # PIL Image\n",
    "#                 image.save(temp_img_path)\n",
    "#                 image_path = temp_img_path\n",
    "#                 print(f\"[DEBUG] Saved PIL image to: {image_path}\")\n",
    "#             else:\n",
    "#                 # Skip image processing if we can't handle the type\n",
    "#                 print(f\"[DEBUG] Unsupported image type: {type(image)}\")\n",
    "#                 image_path = None\n",
    "            \n",
    "#             if image_path and os.path.exists(image_path):\n",
    "#                 print(f\"[DEBUG] Calling analyze_image_with_llava with path: {image_path}\")\n",
    "#                 # Call the analyze_image_with_llava function\n",
    "#                 image_description, keywords = analyze_image_with_llava(image_path)\n",
    "                \n",
    "#                 print(f\"[DEBUG] Image analysis complete. Description: {image_description[:50]}...\")\n",
    "#                 print(f\"[DEBUG] Extracted keywords: {keywords}\")\n",
    "                \n",
    "#                 # Store in session\n",
    "#                 session[\"image_analysis\"] = {\n",
    "#                     \"description\": image_description,\n",
    "#                     \"keywords\": keywords,\n",
    "#                     \"image_path\": image_path\n",
    "#                 }\n",
    "                \n",
    "#                 # Enhance the search query with keywords\n",
    "#                 if keywords:\n",
    "#                     keyword_str = \" \".join(keywords)\n",
    "#                     if search_query:\n",
    "#                         search_query = f\"{search_query} {keyword_str}\"\n",
    "#                     else:\n",
    "#                         search_query = keyword_str\n",
    "#                     print(f\"[DEBUG] Enhanced search query: {search_query}\")\n",
    "                \n",
    "#                 # If we just have an image with no text query, we'll acknowledge the image\n",
    "#                 if not user_input or user_input.strip() == \"\":\n",
    "#                     # Add initial response about the image\n",
    "#                     image_response = {\"role\": \"assistant\", \"content\": f\"I can see the item in your image. It looks like {image_description[:150]}...\"}\n",
    "#                     follow_up = {\"role\": \"assistant\", \"content\": \"Is there anything specific about this item you're looking for? Or shall I find similar products?\"}\n",
    "                    \n",
    "#                     # Add this interaction to conversation history\n",
    "#                     session[\"conversation_history\"].append({\"role\": \"user\", \"content\": f\"[Uploaded an image]\"})\n",
    "#                     session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": image_response[\"content\"]})\n",
    "#                     session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": follow_up[\"content\"]})\n",
    "                    \n",
    "#                     # Update criteria from image analysis\n",
    "#                     for keyword in keywords:\n",
    "#                         # Try to identify item type\n",
    "#                         item_types = [\"jacket\", \"dress\", \"shirt\", \"pants\", \"jeans\", \"skirt\", \"sweater\", \"coat\", \n",
    "#                                      \"blouse\", \"hoodie\", \"blazer\", \"suit\", \"shorts\", \"top\"]\n",
    "#                         if keyword.lower() in item_types and \"item_type\" not in session[\"criteria_collected\"]:\n",
    "#                             session[\"criteria_collected\"][\"item_type\"] = keyword\n",
    "                            \n",
    "#                         # Try to identify color\n",
    "#                         colors = [\"black\", \"white\", \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"pink\", \n",
    "#                                  \"orange\", \"grey\", \"gray\", \"brown\", \"navy\", \"beige\"]\n",
    "#                         if keyword.lower() in colors and \"color\" not in session[\"criteria_collected\"]:\n",
    "#                             session[\"criteria_collected\"][\"color\"] = keyword\n",
    "                    \n",
    "#                     return [image_response, follow_up]\n",
    "#         except Exception as e:\n",
    "#             print(f\"[ERROR] Exception during image processing: {e}\")\n",
    "#             # Continue without image analysis\n",
    "    \n",
    "#     # Add user message to conversation history if there is one\n",
    "#     if user_input and user_input.strip():\n",
    "#         session[\"conversation_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "#     # Have AI analyze the message and context\n",
    "#     try:\n",
    "#         # Create a context-aware prompt for the AI\n",
    "#         prompt = f\"\"\"\n",
    "# You are a fashion shopping assistant helping a customer find products. Analyze their latest message and previous conversation to:\n",
    "\n",
    "# 1. Extract shopping criteria (if any)\n",
    "# 2. Determine what the conversation needs next\n",
    "# 3. Format your response as JSON\n",
    "\n",
    "# Previous conversation:\n",
    "# {json.dumps(session[\"conversation_history\"][:-1])[:1000] if len(session[\"conversation_history\"]) > 1 else \"This is the start of the conversation.\"}\n",
    "\n",
    "# Current criteria collected:\n",
    "# {json.dumps(session[\"criteria_collected\"])}\n",
    "\n",
    "# Current stage: {session[\"stage\"]}\n",
    "# Recommendations shown: {\"Yes\" if session[\"recommendations_shown\"] else \"No\"}\n",
    "# {\"Image analysis: \" + json.dumps(session[\"image_analysis\"]) if session.get(\"image_analysis\") else \"No image uploaded\"}\n",
    "\n",
    "# Latest user message: \"{user_input}\"\n",
    "\n",
    "# Respond with JSON only, in this format:\n",
    "# {{\n",
    "#   \"extracted_criteria\": {{\n",
    "#     \"item_type\": \"detected item or null\",\n",
    "#     \"style\": \"detected style or null\",\n",
    "#     \"color\": \"detected color or null\", \n",
    "#     \"occasion\": \"detected occasion or null\",\n",
    "#     \"price_range\": \"detected price range or null\",\n",
    "#     \"other\": \"any other important criteria detected\"\n",
    "#   }},\n",
    "#   \"action\": \"one of: greet, ask_for_criteria, search_products, show_more, restart, answer_question\",\n",
    "#   \"missing_criterion\": \"most important missing criterion to ask about or null\",\n",
    "#   \"question\": \"follow-up question to ask (if applicable) or null\",\n",
    "#   \"understanding\": \"brief summary of what you understand about their needs\",\n",
    "#   \"ready_to_search\": true/false,\n",
    "#   \"search_query\": \"optimized search query based on all criteria and context\"\n",
    "# }}\n",
    "\n",
    "# Important: \n",
    "# - The extracted_criteria should ONLY include values you're confident about from the current message or previous context\n",
    "# - Do NOT invent criteria not mentioned by the user\n",
    "# - For action, use \"search_products\" only when you have enough criteria OR the user is clearly asking to see products\n",
    "# - For search_query, optimize the terms for product search (remove filler words, focus on key features)\n",
    "# \"\"\"\n",
    "\n",
    "#         # Send to Ollama for analysis\n",
    "#         response = ollama.chat(\n",
    "#             model=\"mistral\", \n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "        \n",
    "#         # Parse the JSON response\n",
    "#         analysis_text = response[\"message\"][\"content\"]\n",
    "#         # Find the JSON part in case there's additional text\n",
    "#         json_start = analysis_text.find('{')\n",
    "#         json_end = analysis_text.rfind('}') + 1\n",
    "        \n",
    "#         if json_start >= 0 and json_end > json_start:\n",
    "#             json_part = analysis_text[json_start:json_end]\n",
    "#             analysis = json.loads(json_part)\n",
    "#         else:\n",
    "#             # Fallback if JSON parsing fails\n",
    "#             raise ValueError(\"Could not extract valid JSON from the response\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"[ERROR] Error analyzing message: {e}\")\n",
    "#         # Fallback analysis if there's an error\n",
    "#         analysis = {\n",
    "#             \"extracted_criteria\": {},\n",
    "#             \"action\": \"search_products\" if \"show me\" in user_input.lower() or image is not None else \"ask_for_criteria\",\n",
    "#             \"missing_criterion\": \"item_type\",\n",
    "#             \"question\": \"What type of clothing are you looking for?\",\n",
    "#             \"understanding\": \"I'm trying to understand what you're looking for.\",\n",
    "#             \"ready_to_search\": False,\n",
    "#             \"search_query\": search_query\n",
    "#         }\n",
    "    \n",
    "#     # Update session with extracted criteria\n",
    "#     for criterion, value in analysis[\"extracted_criteria\"].items():\n",
    "#         if value and value.lower() not in (\"null\", \"none\"):\n",
    "#             session[\"criteria_collected\"][criterion] = value\n",
    "    \n",
    "#     # Handle different conversation actions\n",
    "#     if analysis[\"action\"] == \"greet\":\n",
    "#         session[\"stage\"] = \"collecting\"\n",
    "#         return [{\"role\": \"assistant\", \"content\": f\"Hi! I'd be happy to help you find the perfect outfit. You can describe what you're looking for or upload an image. {analysis.get('question', 'What type of clothing are you looking for today?')}\"}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"ask_for_criteria\":\n",
    "#         session[\"stage\"] = \"collecting\"\n",
    "#         question = analysis.get(\"question\") or f\"Can you tell me what kind of {analysis.get('missing_criterion', 'item')} you're looking for?\"\n",
    "#         return [{\"role\": \"assistant\", \"content\": question}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"search_products\" or analysis[\"action\"] == \"show_more\":\n",
    "#         session[\"stage\"] = \"searching\"\n",
    "#         # Use the existing retrieve_relevant_products and generate_rag_response functions\n",
    "#         search_query = analysis.get(\"search_query\") or search_query\n",
    "        \n",
    "#         # If we have image analysis, incorporate it into the search (if not already in search_query)\n",
    "#         if session.get(\"image_analysis\") and session[\"image_analysis\"].get(\"keywords\"):\n",
    "#             # Check if keywords are already in the query\n",
    "#             keyword_present = False\n",
    "#             for keyword in session[\"image_analysis\"][\"keywords\"]:\n",
    "#                 if keyword.lower() in search_query.lower():\n",
    "#                     keyword_present = True\n",
    "#                     break\n",
    "            \n",
    "#             if not keyword_present:\n",
    "#                 keyword_str = \" \".join(session[\"image_analysis\"][\"keywords\"])\n",
    "#                 search_query = f\"{search_query} {keyword_str}\"\n",
    "#                 print(f\"[DEBUG] Added image keywords to search query: {search_query}\")\n",
    "        \n",
    "#         # Get AI-generated recommendations\n",
    "#         print(f\"[DEBUG] Calling generate_rag_response with query: {search_query}\")\n",
    "#         recommendations = generate_rag_response(search_query, session[\"criteria_collected\"], session)\n",
    "        \n",
    "#         if not recommendations:\n",
    "#             # No products found - ask if user wants to broaden search\n",
    "#             session[\"recommendations_shown\"] = True\n",
    "#             return [{\"role\": \"assistant\", \"content\": \"I couldn't find any products matching your criteria. Could you be more general or try different options?\"}]\n",
    "        \n",
    "#         # Create structured response list\n",
    "#         response_list = []\n",
    "        \n",
    "#         # First, summarize what we understood from their requirements\n",
    "#         criteria_display = {\n",
    "#             \"item_type\": \"Item\", \n",
    "#             \"style\": \"Style\", \n",
    "#             \"color\": \"Color\", \n",
    "#             \"occasion\": \"Occasion\", \n",
    "#             \"price_range\": \"Price\",\n",
    "#             \"other\": \"Other\"\n",
    "#         }\n",
    "        \n",
    "#         criteria_summary = \", \".join([f\"{criteria_display[k]}: {v}\" for k, v in session[\"criteria_collected\"].items() \n",
    "#                                       if v and k in criteria_display])\n",
    "        \n",
    "#         # If we have image analysis, mention it\n",
    "#         if session.get(\"image_analysis\"):\n",
    "#             if criteria_summary:\n",
    "#                 response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image and preferences ({criteria_summary}), here are some recommendations:\"})\n",
    "#             else:\n",
    "#                 response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image, here are some similar products:\"})\n",
    "#         elif criteria_summary:\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": f\"Here are some recommendations based on your preferences ({criteria_summary}):\"})\n",
    "#         else:\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": \"Here are some recommendations based on your request:\"})\n",
    "        \n",
    "#         # Add products with images and descriptions\n",
    "#         for rec in recommendations:\n",
    "#             try:\n",
    "#                 images = ast.literal_eval(rec[\"images\"])\n",
    "#             except:\n",
    "#                 # Fallback if images can't be parsed\n",
    "#                 images = [rec[\"image\"]]\n",
    "            \n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # Product with AI explanation\n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "#                                                                           columns=4, \n",
    "#                                                                           rows=1, \n",
    "#                                                                           object_fit=\"cover\", \n",
    "#                                                                           height=\"automatic\",\n",
    "#                                                                           allow_preview=True)\n",
    "#                                                                          }) \n",
    "    \n",
    "#             response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds spacing\n",
    "    \n",
    "#         # Add follow-up prompt\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": \"Would you like to see more options, or should I help you find something else?\"})\n",
    "        \n",
    "#         # Update session\n",
    "#         session[\"recommendations_shown\"] = True\n",
    "#         session[\"stage\"] = \"recommending\"\n",
    "        \n",
    "#         # Add assistant response to conversation history\n",
    "#         session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": \"I showed some product recommendations based on the user's criteria.\"})\n",
    "        \n",
    "#         return response_list\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"restart\":\n",
    "#         # Reset the session (redundant with the check at the beginning, but keeping for completeness)\n",
    "#         session[\"criteria_collected\"] = {}\n",
    "#         session[\"stage\"] = \"collecting\" \n",
    "#         session[\"recommendations_shown\"] = False\n",
    "#         session[\"conversation_history\"] = []\n",
    "#         session[\"image_analysis\"] = None\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "#     elif analysis[\"action\"] == \"answer_question\":\n",
    "#         # If the AI detects a question not related to product search\n",
    "#         if \"question\" in analysis and analysis[\"question\"]:\n",
    "#             return [{\"role\": \"assistant\", \"content\": analysis[\"question\"]}]\n",
    "#         else:\n",
    "#             return [{\"role\": \"assistant\", \"content\": \"I'm here to help you find fashion products. What kind of item are you looking for?\"}]\n",
    "    \n",
    "#     # Default fallback response if analysis doesn't yield actionable results\n",
    "#     return [{\"role\": \"assistant\", \"content\": \"I'm not sure I understood. Could you tell me what kind of clothing or fashion item you're looking for? You can also upload an image if you have one.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_fashion_assistant(user_input, image=None, history=None, session_id=\"default\"):\n",
    "    \"\"\"\n",
    "    AI-powered conversational shopping assistant with improved error handling.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's text message\n",
    "        image (Image, optional): Uploaded image for visual search. Defaults to None.\n",
    "        history (list, optional): Chat history. Defaults to None.\n",
    "        session_id (str, optional): Unique session identifier. Defaults to \"default\".\n",
    "    \n",
    "    Returns:\n",
    "        list: List of response messages\n",
    "    \"\"\"\n",
    "    # Initialize history if None\n",
    "    if history is None:\n",
    "        history = []\n",
    "    \n",
    "    # Get or create session\n",
    "    session = user_sessions[session_id]\n",
    "    \n",
    "    # Handle special restart requests\n",
    "    restart_phrases = [\"start over\", \"restart\", \"reset\", \"new search\", \"start again\"]\n",
    "    if user_input and any(phrase in user_input.lower() for phrase in restart_phrases):\n",
    "        # Reset the session\n",
    "        session[\"criteria_collected\"] = {}\n",
    "        session[\"stage\"] = \"initial\"\n",
    "        session[\"recommendations_shown\"] = False\n",
    "        session[\"conversation_history\"] = []\n",
    "        session[\"image_analysis\"] = None\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "    # Handle empty inputs gracefully\n",
    "    if not user_input.strip() and image is None:\n",
    "        # If there's truly no input, provide a greeting/help message\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Hi there! I can help you find clothing items. What are you looking for today? You can also upload an image if you have something specific in mind.\"}]\n",
    "    \n",
    "    # Handle image upload if present\n",
    "    search_query = user_input if user_input else \"\"\n",
    "    image_description = None\n",
    "    \n",
    "    if image is not None:\n",
    "        try:\n",
    "            # Process the image\n",
    "            import os\n",
    "            import tempfile\n",
    "            from PIL import Image as PILImage\n",
    "            \n",
    "            print(f\"[DEBUG] Image detected in chat input\")\n",
    "            \n",
    "            # Save the uploaded image to a temporary file if needed\n",
    "            if isinstance(image, str) and os.path.exists(image):\n",
    "                image_path = image\n",
    "                print(f\"[DEBUG] Using existing image path: {image_path}\")\n",
    "            else:\n",
    "                # Handle PIL Image or other image types\n",
    "                temp_dir = tempfile.gettempdir()\n",
    "                temp_img_path = os.path.join(temp_dir, f\"upload_{os.urandom(4).hex()}.jpg\")\n",
    "                \n",
    "                if hasattr(image, 'save'):  # PIL Image\n",
    "                    image.save(temp_img_path)\n",
    "                    image_path = temp_img_path\n",
    "                    print(f\"[DEBUG] Saved PIL image to: {image_path}\")\n",
    "                else:\n",
    "                    print(f\"[DEBUG] Unsupported image type: {type(image)}\")\n",
    "                    image_path = None\n",
    "            \n",
    "            if image_path and os.path.exists(image_path):\n",
    "                print(f\"[DEBUG] Calling analyze_image_with_llava with path: {image_path}\")\n",
    "                # Call the analyze_image_with_llava function\n",
    "                image_description, keywords = analyze_image_with_llava(image_path, user_input)\n",
    "                \n",
    "                print(f\"[DEBUG] Image analysis complete. Description: {image_description[:50]}...\")\n",
    "                print(f\"[DEBUG] Extracted keywords: {keywords}\")\n",
    "                \n",
    "                # Store in session\n",
    "                session[\"image_analysis\"] = {\n",
    "                    \"description\": image_description,\n",
    "                    \"keywords\": keywords,\n",
    "                    \"image_path\": image_path\n",
    "                }\n",
    "                \n",
    "                # Enhance the search query with keywords\n",
    "                if keywords:\n",
    "                    keyword_str = \" \".join(keywords)\n",
    "                    if search_query:\n",
    "                        search_query = f\"{search_query} {keyword_str}\"\n",
    "                    else:\n",
    "                        search_query = keyword_str\n",
    "                    print(f\"[DEBUG] Enhanced search query: {search_query}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Exception during image processing: {e}\")\n",
    "            # Continue without image analysis\n",
    "    \n",
    "    # Add user message to conversation history\n",
    "    # IMPORTANT: Make sure we're storing the exact message that was input, not a modified version\n",
    "    # This ensures different messages remain separate\n",
    "    session[\"conversation_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # If we have image analysis, acknowledge it\n",
    "    if image is not None and image_description:\n",
    "        # Add initial response about the image\n",
    "        image_response = {\"role\": \"assistant\", \"content\": f\"I can see the item in your image. It looks like {image_description[:100]}...\"}\n",
    "        \n",
    "        # If there's no text query, ask for more details and return\n",
    "        if not user_input.strip():\n",
    "            session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": image_response[\"content\"]})\n",
    "            return [image_response, {\"role\": \"assistant\", \"content\": \"Is there anything specific about this item you're looking for? Or shall I find similar products?\"}]\n",
    "    \n",
    "    # Have AI analyze the message and context\n",
    "    try:\n",
    "        # Create a context-aware prompt for the AI\n",
    "        prompt = f\"\"\"\n",
    "You are a fashion shopping assistant helping a customer find products. Analyze their latest message and previous conversation to:\n",
    "\n",
    "1. Extract shopping criteria (if any)\n",
    "2. Determine what the conversation needs next\n",
    "3. Format your response as JSON\n",
    "\n",
    "Previous conversation:\n",
    "{json.dumps(session[\"conversation_history\"][:-1])[:1000] if len(session[\"conversation_history\"]) > 1 else \"This is the start of the conversation.\"}\n",
    "\n",
    "Current criteria collected:\n",
    "{json.dumps(session[\"criteria_collected\"])}\n",
    "\n",
    "Current stage: {session[\"stage\"]}\n",
    "Recommendations shown: {\"Yes\" if session[\"recommendations_shown\"] else \"No\"}\n",
    "{\"Image analysis: \" + json.dumps(session[\"image_analysis\"]) if session.get(\"image_analysis\") else \"No image uploaded\"}\n",
    "\n",
    "Latest user message: \"{user_input}\"\n",
    "\n",
    "Respond with JSON only, in this format:\n",
    "{{\n",
    "  \"extracted_criteria\": {{\n",
    "    \"item_type\": \"detected item or null\",\n",
    "    \"style\": \"detected style or null\",\n",
    "    \"color\": \"detected color or null\", \n",
    "    \"occasion\": \"detected occasion or null\",\n",
    "    \"price_range\": \"detected price range or null\",\n",
    "    \"other\": \"any other important criteria detected\"\n",
    "  }},\n",
    "  \"action\": \"one of: greet, ask_for_criteria, search_products, show_more, restart, answer_question\",\n",
    "  \"missing_criterion\": \"most important missing criterion to ask about or null\",\n",
    "  \"question\": \"follow-up question to ask (if applicable) or null\",\n",
    "  \"understanding\": \"brief summary of what you understand about their needs\",\n",
    "  \"ready_to_search\": true/false,\n",
    "  \"search_query\": \"optimized search query based on all criteria and context\"\n",
    "}}\n",
    "\n",
    "Important: \n",
    "- The extracted_criteria should ONLY include values you're confident about from the current message or previous context\n",
    "- Do NOT invent criteria not mentioned by the user\n",
    "- For action, use \"search_products\" only when you have enough criteria OR the user is clearly asking to see products\n",
    "- For search_query, optimize the terms for product search (remove filler words, focus on key features)\n",
    "\"\"\"\n",
    "\n",
    "        # Send to Ollama for analysis\n",
    "        response = ollama.chat(\n",
    "            model=\"mistral\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        analysis_text = response[\"message\"][\"content\"]\n",
    "        # Find the JSON part in case there's additional text\n",
    "        json_start = analysis_text.find('{')\n",
    "        json_end = analysis_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_part = analysis_text[json_start:json_end]\n",
    "            analysis = json.loads(json_part)\n",
    "        else:\n",
    "            # Fallback if JSON parsing fails\n",
    "            raise ValueError(\"Could not extract valid JSON from the response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error analyzing message: {e}\")\n",
    "        # Fallback analysis if there's an error\n",
    "        analysis = {\n",
    "            \"extracted_criteria\": {},\n",
    "            \"action\": \"search_products\" if \"show me\" in user_input.lower() or image is not None else \"ask_for_criteria\",\n",
    "            \"missing_criterion\": \"item_type\",\n",
    "            \"question\": \"What type of clothing are you looking for?\",\n",
    "            \"understanding\": \"I'm trying to understand what you're looking for.\",\n",
    "            \"ready_to_search\": False,\n",
    "            \"search_query\": search_query\n",
    "        }\n",
    "    \n",
    "    # Update session with extracted criteria - FIX THE ERROR HERE\n",
    "    for criterion, value in analysis[\"extracted_criteria\"].items():\n",
    "        if value:  # Just check if value exists\n",
    "            # Check type to prevent errors\n",
    "            if isinstance(value, str) and value.lower() not in (\"null\", \"none\"):\n",
    "                session[\"criteria_collected\"][criterion] = value\n",
    "            elif isinstance(value, (list, dict)):\n",
    "                # Handle complex value types properly\n",
    "                session[\"criteria_collected\"][criterion] = value\n",
    "            # Skip None values and empty strings\n",
    "    \n",
    "    # Handle different conversation actions\n",
    "    if analysis[\"action\"] == \"greet\":\n",
    "        session[\"stage\"] = \"collecting\"\n",
    "        return [{\"role\": \"assistant\", \"content\": f\"Hi! I'd be happy to help you find the perfect outfit. You can describe what you're looking for or upload an image. {analysis.get('question', 'What type of clothing are you looking for today?')}\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"ask_for_criteria\":\n",
    "        session[\"stage\"] = \"collecting\"\n",
    "        question = analysis.get(\"question\") or f\"Can you tell me what kind of {analysis.get('missing_criterion', 'item')} you're looking for?\"\n",
    "        return [{\"role\": \"assistant\", \"content\": question}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"search_products\" or analysis[\"action\"] == \"show_more\":\n",
    "        session[\"stage\"] = \"searching\"\n",
    "        # Use the existing retrieve_relevant_products and generate_rag_response functions\n",
    "        search_query = analysis.get(\"search_query\") or search_query\n",
    "        \n",
    "        # If we have image analysis, incorporate it into the search (if not already in search_query)\n",
    "        if session.get(\"image_analysis\") and session[\"image_analysis\"].get(\"keywords\"):\n",
    "            # Check if keywords are already in the query\n",
    "            keyword_present = False\n",
    "            for keyword in session[\"image_analysis\"][\"keywords\"]:\n",
    "                if keyword.lower() in search_query.lower():\n",
    "                    keyword_present = True\n",
    "                    break\n",
    "            \n",
    "            if not keyword_present:\n",
    "                keyword_str = \" \".join(session[\"image_analysis\"][\"keywords\"])\n",
    "                search_query = f\"{search_query} {keyword_str}\"\n",
    "                print(f\"[DEBUG] Added image keywords to search query: {search_query}\")\n",
    "        \n",
    "        # Get AI-generated recommendations\n",
    "        print(f\"[DEBUG] Calling generate_rag_response with query: {search_query}\")\n",
    "        try:\n",
    "            recommendations = generate_rag_response(search_query, session[\"criteria_collected\"], session)\n",
    "            \n",
    "            if not recommendations:\n",
    "                # No products found - ask if user wants to broaden search\n",
    "                session[\"recommendations_shown\"] = True\n",
    "                return [{\"role\": \"assistant\", \"content\": \"I couldn't find any products matching your criteria. Could you be more general or try different options?\"}]\n",
    "            \n",
    "            # Create structured response list\n",
    "            response_list = []\n",
    "            \n",
    "            # First, summarize what we understood from their requirements\n",
    "            criteria_display = {\n",
    "                \"item_type\": \"Item\", \n",
    "                \"style\": \"Style\", \n",
    "                \"color\": \"Color\", \n",
    "                \"occasion\": \"Occasion\", \n",
    "                \"price_range\": \"Price\",\n",
    "                \"other\": \"Other\"\n",
    "            }\n",
    "            \n",
    "            criteria_summary = \", \".join([f\"{criteria_display[k]}: {v}\" for k, v in session[\"criteria_collected\"].items() \n",
    "                                        if v and k in criteria_display])\n",
    "            \n",
    "            # If we have image analysis, mention it\n",
    "            if session.get(\"image_analysis\"):\n",
    "                if criteria_summary:\n",
    "                    response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image and preferences ({criteria_summary}), here are some recommendations:\"})\n",
    "                else:\n",
    "                    response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image, here are some similar products:\"})\n",
    "            elif criteria_summary:\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": f\"Here are some recommendations based on your preferences ({criteria_summary}):\"})\n",
    "            else:\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": \"Here are some recommendations based on your request:\"})\n",
    "            \n",
    "            # Add products with images and descriptions\n",
    "            for rec in recommendations:\n",
    "                try:\n",
    "                    images = ast.literal_eval(rec[\"images\"])\n",
    "                except:\n",
    "                    # Fallback if images can't be parsed\n",
    "                    images = [rec[\"image\"]]\n",
    "                \n",
    "                response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # Product with AI explanation\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "                                                                            columns=4, \n",
    "                                                                            rows=1, \n",
    "                                                                            object_fit=\"cover\", \n",
    "                                                                            height=\"automatic\",\n",
    "                                                                            allow_preview=True)\n",
    "                                                                            }) \n",
    "            \n",
    "                response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds spacing\n",
    "            \n",
    "            # Add follow-up prompt\n",
    "            response_list.append({\"role\": \"assistant\", \"content\": \"Would you like to see more options, or should I help you find something else?\"})\n",
    "            \n",
    "            # Update session\n",
    "            session[\"recommendations_shown\"] = True\n",
    "            session[\"stage\"] = \"recommending\"\n",
    "            \n",
    "            # Add assistant response to conversation history\n",
    "            session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": \"I showed some product recommendations based on the user's criteria.\"})\n",
    "            \n",
    "            return response_list\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Exception during recommendation generation: {e}\")\n",
    "            # Provide a fallback response\n",
    "            return [{\"role\": \"assistant\", \"content\": \"I'm sorry, I encountered an error while searching for products. Could you try a different query?\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"restart\":\n",
    "        # Reset the session (redundant with the check at the beginning, but keeping for completeness)\n",
    "        session[\"criteria_collected\"] = {}\n",
    "        session[\"stage\"] = \"collecting\" \n",
    "        session[\"recommendations_shown\"] = False\n",
    "        session[\"conversation_history\"] = []\n",
    "        session[\"image_analysis\"] = None\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"answer_question\":\n",
    "        # If the AI detects a question not related to product search\n",
    "        if \"question\" in analysis and analysis[\"question\"]:\n",
    "            return [{\"role\": \"assistant\", \"content\": analysis[\"question\"]}]\n",
    "        else:\n",
    "            return [{\"role\": \"assistant\", \"content\": \"I'm here to help you find fashion products. What kind of item are you looking for?\"}]\n",
    "    \n",
    "    # Default fallback response if analysis doesn't yield actionable results\n",
    "    return [{\"role\": \"assistant\", \"content\": \"I'm not sure I understood. Could you tell me what kind of clothing or fashion item you're looking for? You can also upload an image if you have one.\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: \n",
    "- Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_ui = gr.ChatInterface(\n",
    "#     fn=chat_fashion_assistant,\n",
    "#     title=\"ðŸ›ï¸ ShopGPT\",\n",
    "#     description=\"Describe what you're looking for and get personalized recommendations!\",\n",
    "#     type=\"messages\",  # Uses Gradio's structured chat format\n",
    "#     theme='allenai/gradio-theme'\n",
    "# )\n",
    "\n",
    "# chat_ui.launch(share=True, server_port = 7877)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the chat interface with additional components\n",
    "# with gr.Blocks(theme='allenai/gradio-theme') as app:\n",
    "#     # Header section\n",
    "#     with gr.Row():\n",
    "#         with gr.Column(scale=8):\n",
    "#             gr.Markdown(\"# ðŸ›ï¸ ShopGPT\")\n",
    "#             gr.Markdown(\"Describe what you're looking for and get personalized recommendations!\")\n",
    "#         with gr.Column(scale=1):\n",
    "#             close_button = gr.Button(\n",
    "#                 \"â¹ï¸\", # Unicode stop button symbol\n",
    "#                 size=\"sm\",\n",
    "#                 variant=\"secondary\",\n",
    "#                 elem_classes=\"close-btn\"\n",
    "#             )\n",
    "    \n",
    "#     # Main chat interface\n",
    "#     chatbot = gr.ChatInterface(\n",
    "#         fn=chat_fashion_assistant,\n",
    "#         type=\"messages\",\n",
    "#     )\n",
    "    \n",
    "#     # Add custom CSS\n",
    "#     gr.HTML(\"\"\"\n",
    "#         <style>\n",
    "#         .close-btn {\n",
    "#             position: absolute;\n",
    "#             top: 10px;\n",
    "#             right: 10px;\n",
    "#             min-width: 40px !important;\n",
    "#             font-size: 12px;\n",
    "#             opacity: 0.7;\n",
    "#         }\n",
    "#         .close-btn:hover {\n",
    "#             opacity: 1;\n",
    "#         }\n",
    "#         </style>\n",
    "#     \"\"\")\n",
    "    \n",
    "#     # Connect the button to the shutdown function\n",
    "#     close_button.click(fn=lambda: app.close())\n",
    "\n",
    "# # Launch with fixed port\n",
    "# app.launch(share=True, server_port=7888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_fashion_interface():\n",
    "#     \"\"\"\n",
    "#     Creates a reliable ShopGPT interface that properly displays responses\n",
    "#     \"\"\"\n",
    "#     with gr.Blocks(theme='allenai/gradio-theme') as app:\n",
    "#         gr.Markdown(\"# ðŸ›ï¸ ShopGPT\")\n",
    "#         gr.Markdown(\"I'll help you find the perfect outfit! Describe what you're looking for or upload an image.\")\n",
    "        \n",
    "#         # Simple chatbot with minimal configuration to avoid display issues\n",
    "#         chatbot = gr.Chatbot(\n",
    "#             height=600,\n",
    "#             show_copy_button=False,\n",
    "#             bubble_full_width=False,\n",
    "#         )\n",
    "        \n",
    "#         # Add image preview area\n",
    "#         with gr.Row(visible=False) as image_preview_row:\n",
    "#             image_preview = gr.Image(\n",
    "#                 type=\"filepath\", \n",
    "#                 label=\"Uploaded Image\", \n",
    "#                 height=150,\n",
    "#                 interactive=False\n",
    "#             )\n",
    "        \n",
    "#         with gr.Row():\n",
    "#             # Text input\n",
    "#             msg = gr.Textbox(\n",
    "#                 placeholder=\"Describe what you're looking for or ask questions about fashion items...\",\n",
    "#                 label=\"Your message\",\n",
    "#                 show_label=False,\n",
    "#                 scale=8\n",
    "#             )\n",
    "            \n",
    "#             # Image upload button\n",
    "#             image_btn = gr.UploadButton(\n",
    "#                 \"ðŸ“·\", \n",
    "#                 file_types=[\"image\"], \n",
    "#                 file_count=\"single\",\n",
    "#                 scale=1\n",
    "#             )\n",
    "            \n",
    "#             # Send button\n",
    "#             submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "        \n",
    "#         # Hidden state for storing the uploaded image\n",
    "#         current_image = gr.State(None)\n",
    "        \n",
    "#         with gr.Row():\n",
    "#             # Clear button\n",
    "#             clear_btn = gr.Button(\"Start New Chat\", scale=5)\n",
    "            \n",
    "#             # Discrete close server button\n",
    "#             close_btn = gr.Button(\"Close Server\", scale=1, variant=\"stop\")\n",
    "        \n",
    "#         # Example queries\n",
    "#         examples = gr.Examples(\n",
    "#             examples=[\n",
    "#                 [\"I need a casual jacket for cool weather\"],\n",
    "#                 [\"Looking for a formal dress for a wedding\"],\n",
    "#                 [\"Show me some comfortable running shoes\"],\n",
    "#                 [\"I need something professional for job interviews\"]\n",
    "#             ],\n",
    "#             inputs=msg\n",
    "#         )\n",
    "        \n",
    "#         # Update the current image when uploaded\n",
    "#         def update_image(file):\n",
    "#             if file:\n",
    "#                 filename = file.name.split(\"/\")[-1] if \"/\" in file.name else file.name\n",
    "#                 return file.name, gr.Row(visible=True), file.name\n",
    "#             return None, gr.Row(visible=False), None\n",
    "        \n",
    "#         # Update when image is uploaded\n",
    "#         image_btn.upload(\n",
    "#             update_image, \n",
    "#             image_btn, \n",
    "#             [current_image, image_preview_row, image_preview]\n",
    "#         )\n",
    "        \n",
    "#         # Handle user message and generate response\n",
    "#         def respond(message, image_path, chat_history):\n",
    "#             # Skip if there's no input\n",
    "#             if not message.strip() and not image_path:\n",
    "#                 return chat_history, None, gr.Row(visible=False), None, \"\"\n",
    "            \n",
    "#             # First add user message to chat\n",
    "#             if message.strip():\n",
    "#                 chat_history.append([message, None])\n",
    "#             elif image_path:\n",
    "#                 chat_history.append([\"[Looking for items similar to uploaded image]\", None])\n",
    "            \n",
    "#             # Prepare image data if available\n",
    "#             image_data = None\n",
    "#             if image_path:\n",
    "#                 try:\n",
    "#                     from PIL import Image\n",
    "#                     image_data = Image.open(image_path)\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error loading image: {e}\")\n",
    "            \n",
    "#             # Get response from assistant\n",
    "#             try:\n",
    "#                 # Construct appropriate message\n",
    "#                 query = message if message.strip() else \"Find products like this image\"\n",
    "                \n",
    "#                 # Call the assistant - ensure it returns a list of responses\n",
    "#                 responses = chat_fashion_assistant(query, image_data, chat_history)\n",
    "                \n",
    "#                 # Make sure we have a valid response list\n",
    "#                 if not responses or not isinstance(responses, list):\n",
    "#                     # Fallback for empty or invalid response\n",
    "#                     responses = [{\"role\": \"assistant\", \"content\": \"I'm not sure how to respond to that. Could you try asking another way?\"}]\n",
    "                \n",
    "#                 # Process each response\n",
    "#                 for response in responses:\n",
    "#                     # Handle each individual response\n",
    "#                     if isinstance(response, dict) and \"content\" in response:\n",
    "#                         # If the last message in chat_history has no assistant response yet, update it\n",
    "#                         if chat_history and chat_history[-1][1] is None:\n",
    "#                             chat_history[-1][1] = response[\"content\"]\n",
    "#                         else:\n",
    "#                             # Otherwise add a new message pair with None for user and response for assistant\n",
    "#                             chat_history.append([None, response[\"content\"]])\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error generating response: {e}\")\n",
    "#                 import traceback\n",
    "#                 traceback.print_exc()\n",
    "#                 # Add fallback response in case of exception\n",
    "#                 if chat_history and chat_history[-1][1] is None:\n",
    "#                     chat_history[-1][1] = \"Sorry, I encountered an error. Please try again.\"\n",
    "#                 else:\n",
    "#                     chat_history.append([None, \"Sorry, I encountered an error. Please try again.\"])\n",
    "            \n",
    "#             # Clear inputs after processing\n",
    "#             return chat_history, None, gr.Row(visible=False), None, \"\"\n",
    "        \n",
    "#         # Define event handlers\n",
    "#         submit_btn.click(\n",
    "#             respond, \n",
    "#             inputs=[msg, current_image, chatbot], \n",
    "#             outputs=[chatbot, current_image, image_preview_row, image_preview, msg],\n",
    "#             queue=True\n",
    "#         )\n",
    "        \n",
    "#         msg.submit(\n",
    "#             respond, \n",
    "#             inputs=[msg, current_image, chatbot], \n",
    "#             outputs=[chatbot, current_image, image_preview_row, image_preview, msg],\n",
    "#             queue=True\n",
    "#         )\n",
    "        \n",
    "#         # Clear everything \n",
    "#         def clear_all():\n",
    "#             return [], None, gr.Row(visible=False), None, \"\"\n",
    "        \n",
    "#         clear_btn.click(clear_all, None, [chatbot, current_image, image_preview_row, image_preview, msg], queue=False)\n",
    "        \n",
    "#         # Add close server functionality with simple approach\n",
    "#         def close_server():\n",
    "#             app.close()\n",
    "            \n",
    "#         close_btn.click(close_server, None, None, queue=False)\n",
    "        \n",
    "#         # Add simple debug function to trace message flow\n",
    "#         def trace_message_flow():\n",
    "#             print(\"\\nShopGPT message flow tracing is active\")\n",
    "#             print(\"Check console for error messages if responses don't appear\\n\")\n",
    "#             return None\n",
    "            \n",
    "#         app.load(trace_message_flow, None, None)\n",
    "        \n",
    "#     return app\n",
    "\n",
    "# # Create and launch the interface\n",
    "# shop_gpt = create_fashion_interface()\n",
    "# shop_gpt.launch(share=True, server_port = 7888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/ipykernel_61537/834094478.py:11: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/ipykernel_61537/834094478.py:11: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://7e065bd01ff508c0f8.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7e065bd01ff508c0f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Error analyzing message: Expecting ',' delimiter: line 3 column 43 (char 72)\n",
      "[DEBUG] Image detected in chat input\n",
      "[DEBUG] Saved PIL image to: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_2698b3f9.jpg\n",
      "[DEBUG] Calling analyze_image_with_llava with path: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_2698b3f9.jpg\n",
      "[DEBUG] Starting image analysis for: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_2698b3f9.jpg\n",
      "[DEBUG] Query-aware analysis with: 'Find products like this image'\n",
      "[DEBUG] LLaVA output will be saved to: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/llava_output.txt\n",
      "[DEBUG] Executing LLaVA command\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LLaVA command completed successfully\n",
      "[DEBUG] LLaVA output file size: 4258 characters\n",
      "[DEBUG] Found marker line for description start\n",
      "[DEBUG] Extracted description (544 chars): The most prominent clothing item in this image is a parka-style jacket. The jacket features a hood a...\n",
      "[DEBUG] Found KEYWORDS section in output\n",
      "[DEBUG] Successfully extracted 10 keywords: ['hooded', 'oversized', 'loose', 'fitting', 'parka', 'style', 'green', 'buttoned', 'detailing', 'drawstring']\n",
      "[DEBUG] LLaVA analysis completed successfully âœ…\n",
      "[DEBUG] Image analysis complete. Description: The most prominent clothing item in this image is ...\n",
      "[DEBUG] Extracted keywords: ['hooded', 'oversized', 'loose', 'fitting', 'parka', 'style', 'green', 'buttoned', 'detailing', 'drawstring']\n",
      "[DEBUG] Enhanced search query: Find products like this image hooded oversized loose fitting parka style green buttoned detailing drawstring\n",
      "[DEBUG] Calling generate_rag_response with query: green oversized hooded parka jacket\n",
      "Searching for: jacket hooded parka green green oversized hooded parka jacket\n"
     ]
    }
   ],
   "source": [
    "def create_fashion_interface():\n",
    "    \"\"\"\n",
    "    Creates a ShopGPT interface with actual image previews\n",
    "    in both the input area and chat.\n",
    "    \"\"\"\n",
    "    with gr.Blocks(theme='allenai/gradio-theme') as app:\n",
    "        gr.Markdown(\"# ðŸ›ï¸ ShopGPT\")\n",
    "        gr.Markdown(\"I'll help you find the perfect outfit! Describe what you're looking for or upload an image.\")\n",
    "        \n",
    "        # Chatbot component\n",
    "        chatbot = gr.Chatbot(\n",
    "            height=600,\n",
    "            show_copy_button=False,\n",
    "            bubble_full_width=False,\n",
    "        )\n",
    "        \n",
    "        # Loading indicator\n",
    "        with gr.Row(visible=False) as loading_indicator:\n",
    "            gr.Markdown(\"*Generating response...*\")\n",
    "        \n",
    "        # Visual image preview above the textbox\n",
    "        with gr.Row(visible=False) as image_preview_row:\n",
    "            image_preview = gr.Image(\n",
    "                label=\"Image Preview\",\n",
    "                show_label=False,\n",
    "                height=150,\n",
    "                interactive=False,\n",
    "                type=\"filepath\"  # Use filepath for compatibility\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Text input\n",
    "            msg = gr.Textbox(\n",
    "                placeholder=\"Describe what you're looking for or ask questions about fashion items...\",\n",
    "                label=\"Your message\",\n",
    "                show_label=False,\n",
    "                scale=8\n",
    "            )\n",
    "            \n",
    "            # Image upload button\n",
    "            image_btn = gr.UploadButton(\n",
    "                \"ðŸ“·\", \n",
    "                file_types=[\"image\"], \n",
    "                file_count=\"single\",\n",
    "                scale=1\n",
    "            )\n",
    "            \n",
    "            # Send button\n",
    "            submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "        \n",
    "        # Hidden state for storing the uploaded image\n",
    "        current_image = gr.State(None)\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Clear button\n",
    "            clear_btn = gr.Button(\"Start New Chat\", scale=5)\n",
    "            \n",
    "            # Close server button\n",
    "            close_btn = gr.Button(\"Close Server\", scale=1, variant=\"stop\")\n",
    "        \n",
    "        # Example queries\n",
    "        examples = gr.Examples(\n",
    "            examples=[\n",
    "                [\"I need a casual jacket for cool weather\"],\n",
    "                [\"Looking for a formal dress for a wedding\"],\n",
    "                [\"Show me some comfortable running shoes\"],\n",
    "                [\"I need something professional for job interviews\"]\n",
    "            ],\n",
    "            inputs=msg\n",
    "        )\n",
    "        \n",
    "        # Show preview when image is uploaded\n",
    "        def update_image_preview(file):\n",
    "            if file and hasattr(file, 'name'):\n",
    "                # Show the visual preview\n",
    "                return file.name, gr.Row(visible=True), file.name\n",
    "            return None, gr.Row(visible=False), None\n",
    "        \n",
    "        # Update when image is uploaded - show actual preview\n",
    "        image_btn.upload(\n",
    "            update_image_preview, \n",
    "            image_btn, \n",
    "            [current_image, image_preview_row, image_preview]\n",
    "        )\n",
    "        \n",
    "        # STEP 1: Immediately show user message and image in chat\n",
    "        def add_user_message(message, image_path, chat_history):\n",
    "            # Skip if no input provided\n",
    "            if not message.strip() and not image_path:\n",
    "                return chat_history, message, gr.Button(interactive=True)\n",
    "            \n",
    "            # Add user message to chat\n",
    "            if message.strip():\n",
    "                chat_history.append([message, None])\n",
    "            elif image_path:\n",
    "                chat_history.append([\"Looking for items similar to this image\", None])\n",
    "            \n",
    "            # Add actual image to chat if present\n",
    "            if image_path:\n",
    "                try:\n",
    "                    # Add image directly to chat history\n",
    "                    chat_history.append([None, image_path])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding image to chat: {e}\")\n",
    "                    # Fallback to text if image display fails\n",
    "                    chat_history.append([f\"[Image uploaded]\", None])\n",
    "            \n",
    "            # Clear text input and disable send button\n",
    "            return chat_history, \"\", gr.Button(interactive=False)\n",
    "        \n",
    "        # STEP 2: Process the message and generate response\n",
    "        def process_message(message, image_path, chat_history):\n",
    "            # Skip if chat history is empty (edge case)\n",
    "            if not chat_history:\n",
    "                return chat_history, gr.Row(visible=False), None, gr.Button(interactive=True), gr.Row(visible=False)\n",
    "            \n",
    "            try:\n",
    "                # Prepare image for processing (if available)\n",
    "                image_data = None\n",
    "                if image_path:\n",
    "                    try:\n",
    "                        from PIL import Image\n",
    "                        image_data = Image.open(image_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image: {e}\")\n",
    "                \n",
    "                # Construct query\n",
    "                query = message if message.strip() else \"Find products like this image\"\n",
    "                \n",
    "                # Get response from assistant\n",
    "                responses = chat_fashion_assistant(query, image_data, chat_history)\n",
    "                \n",
    "                # Process responses\n",
    "                if responses and isinstance(responses, list):\n",
    "                    for response in responses:\n",
    "                        if isinstance(response, dict) and \"content\" in response:\n",
    "                            chat_history.append([None, response[\"content\"]])\n",
    "                else:\n",
    "                    # Fallback for invalid response\n",
    "                    chat_history.append([None, \"I'm not sure how to respond to that. Could you try asking another way?\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating response: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                chat_history.append([None, \"Sorry, I encountered an error processing your request. Please try again.\"])\n",
    "            \n",
    "            # Reset image preview, re-enable send button, and hide loading indicator\n",
    "            return chat_history, gr.Row(visible=False), None, gr.Button(interactive=True), gr.Row(visible=False)\n",
    "        \n",
    "        # Split the response into two steps for immediate feedback\n",
    "        submit_btn.click(\n",
    "            fn=add_user_message,  # First immediately show user message\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, msg, submit_btn],\n",
    "            queue=False  # No queue for immediate UI update\n",
    "        ).then(\n",
    "            fn=process_message,  # Then process the request (can take time)\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, image_preview_row, current_image, submit_btn, loading_indicator],\n",
    "            queue=True  # Use queue for the actual processing\n",
    "        )\n",
    "        \n",
    "        # Same pattern for text input submit\n",
    "        msg.submit(\n",
    "            fn=add_user_message,\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, msg, submit_btn],\n",
    "            queue=False\n",
    "        ).then(\n",
    "            fn=process_message,\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, image_preview_row, current_image, submit_btn, loading_indicator],\n",
    "            queue=True\n",
    "        )\n",
    "        \n",
    "        # Clear chat and reset all states\n",
    "        def clear_all():\n",
    "            return [], None, \"\", gr.Row(visible=False), None, gr.Button(interactive=True)\n",
    "        \n",
    "        clear_btn.click(\n",
    "            clear_all, \n",
    "            None, \n",
    "            [chatbot, current_image, msg, image_preview_row, image_preview, submit_btn], \n",
    "            queue=False\n",
    "        )\n",
    "        \n",
    "        # Close server\n",
    "        def close_server():\n",
    "            app.close()\n",
    "            \n",
    "        close_btn.click(close_server, None, None, queue=False)\n",
    "        \n",
    "    return app\n",
    "\n",
    "# Create and launch the interface\n",
    "shop_gpt = create_fashion_interface()\n",
    "shop_gpt.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
