{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: \n",
    "- Import df\n",
    "- df = 'url', 'name', 'price', 'color', 'images', 'image link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 url  \\\n",
      "0  https://www.asos.com/new-look/new-look-trench-...   \n",
      "1  https://www.asos.com/stradivarius/stradivarius...   \n",
      "2  https://www.asos.com/jdy/jdy-oversized-trench-...   \n",
      "3  https://www.asos.com/nike-running/nike-running...   \n",
      "4  https://www.asos.com/asos-curve/asos-design-cu...   \n",
      "\n",
      "                                                name  price    color  \\\n",
      "0                      New Look trench coat in camel  49.99  Neutral   \n",
      "1     Stradivarius double breasted wool coat in grey  59.99     GREY   \n",
      "2                 JDY oversized trench coat in stone  45.00    STONE   \n",
      "3                 Nike Running hooded jacket in pink  84.95     Pink   \n",
      "4  ASOS DESIGN Tall linen mix trench coat in natural  75.00  Natural   \n",
      "\n",
      "                                              images  \\\n",
      "0  ['https://images.asos-media.com/products/new-l...   \n",
      "1  ['https://images.asos-media.com/products/strad...   \n",
      "2  ['https://images.asos-media.com/products/jdy-o...   \n",
      "3  ['https://images.asos-media.com/products/nike-...   \n",
      "4  ['https://images.asos-media.com/products/asos-...   \n",
      "\n",
      "                                          image link  \n",
      "0  https://images.asos-media.com/products/new-loo...  \n",
      "1  https://images.asos-media.com/products/stradiv...  \n",
      "2  https://images.asos-media.com/products/jdy-ove...  \n",
      "3  https://images.asos-media.com/products/nike-ru...  \n",
      "4  https://images.asos-media.com/products/asos-de...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CAREFUL WHEN REDUCING:\n",
    "#       Need to delete faiss_index.bin \n",
    "# downloaded = 500\n",
    "num_samples = 100\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./datasets/products.csv\").head(num_samples)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[['url', 'name', 'price', 'color', 'images', 'image link']]\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: (takes time)\n",
    "- Download image\n",
    "- Extract description\n",
    "- Generate description\n",
    "- Apply LLaVa\n",
    "- df = 'url', 'name', 'price', 'color', 'images', 'image link' + description, image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using existing description for New Look trench coat in camel\n",
      "âœ… Using existing description for Stradivarius double breasted wool coat in grey\n",
      "âœ… Using existing description for JDY oversized trench coat in stone\n",
      "âœ… Using existing description for Nike Running hooded jacket in pink\n",
      "âœ… Using existing description for ASOS DESIGN Tall linen mix trench coat in natural\n",
      "âœ… Using existing description for ASOS DESIGN denim bomber in ecru\n",
      "âœ… Using existing description for ASOS Weekend Collective nylon track jacket in neutral\n",
      "âœ… Using existing description for ASOS DESIGN Tall ultimate faux leather biker jacket in black\n",
      "âœ… Using existing description for Native Youth oversized twill shacket co-ord in purple\n",
      "âœ… Using existing description for Carhartt WIP michigan OG jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN denim short sleeve shirt in midwash blue\n",
      "âœ… Using existing description for Bershka maxi belted coat in black\n",
      "âœ… Using existing description for Vero Moda trench coat in black\n",
      "âœ… Using existing description for Stradivarius tailored coat in beige\n",
      "âœ… Using existing description for Stradivarius tailored belted coat in black\n",
      "âœ… Using existing description for Miss Selfridge longline faux leather biker jacket in black\n",
      "âœ… Using existing description for Bershka faux leather motorcross jacket in light grey\n",
      "âœ… Using existing description for Bershka oversized bomber puffer jacket in black\n",
      "âœ… Using existing description for Topshop denim balloon jacket in dirty dark wash\n",
      "âœ… Using existing description for Barbour Annandale diamond quilt jacket with cord collar in navy\n",
      "âœ… Using existing description for ASOS DESIGN borg denim jacket in washed blue\n",
      "âœ… Using existing description for Vero Moda hooded rain jacket in black\n",
      "âœ… Using existing description for New Look Tall trench coat in camel\n",
      "âœ… Using existing description for ASOS DESIGN Petite smart dad coat in black\n",
      "âœ… Using existing description for ASOS DESIGN overhead rain jacket in khaki\n",
      "âœ… Using existing description for New Look quilted belted trench coat in black\n",
      "âœ… Using existing description for ASOS DESIGN high shine bomber jacket in cobalt\n",
      "âœ… Using existing description for New Look mid length padded puffer coat with hood in dark khaki\n",
      "âœ… Using existing description for ASOS DESIGN Curve herringbone shacket in oatmeal\n",
      "âœ… Using existing description for Bershka athletic track jacket in navy\n",
      "âœ… Using existing description for Topshop longline chuck on coat in black\n",
      "âœ… Using existing description for Aria Cove vegan leather trench coat in khaki\n",
      "âœ… Using existing description for Bershka tailored double breasted coat in ecru\n",
      "âœ… Using existing description for ASOS DESIGN Petite trench coat with faux leather hood in black\n",
      "âœ… Using existing description for Under Armour Training Meridian jacket in black\n",
      "âœ… Using existing description for Pull&Bear oversized  bomber jacket in grey\n",
      "âœ… Using existing description for ASOS DESIGN Curve oversized rain parka in black\n",
      "âœ… Using existing description for ASOS 4505 mid layer fleece back jacket with reflective piping\n",
      "âœ… Using existing description for Topshop double breasted coat in green\n",
      "âœ… Using existing description for Topshop Sno borg zip through jacket in green\n",
      "âœ… Using existing description for New Look belted gilet with tie waist detail in light khaki\n",
      "âœ… Using existing description for New Look Curve quilted puffer coat in dark khaki\n",
      "âœ… Using existing description for Topshop Tall sleeveless puffer gilet jacket in off white\n",
      "âœ… Using existing description for Forever New formal wrap coat with tie belt in camel\n",
      "âœ… Using existing description for Topshop oversized collar corduroy bomber jacket in beige\n",
      "âœ… Using existing description for ASOS DESIGN Tall cotton pocket shacket in black\n",
      "âœ… Using existing description for Vero Moda belted wrap coat in beige\n",
      "âœ… Using existing description for In The Style utility pocket detail belted jacket in blue\n",
      "âœ… Using existing description for Noisy May cord oversized shacket in brown\n",
      "âœ… Using existing description for ASOS DESIGN leather ultimate biker jacket in black\n",
      "âœ… Using existing description for Gym King utility gilet in black\n",
      "âœ… Using existing description for River Island faux leather oversized biker jacket in black\n",
      "âœ… Using existing description for Tommy Jeans oversized hooded denim jacket in multi\n",
      "âœ… Using existing description for Topshop textured short coat in grey\n",
      "âœ… Using existing description for NA-KD x Moa Mattsson belted trench coat with faux fur in sage\n",
      "âœ… Using existing description for Topshop borg trench coat in grey\n",
      "âœ… Using existing description for Whistles quilted jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN Petite rubberised rain parka coat in black\n",
      "âœ… Using existing description for Pull&Bear puffer coat with hood in grey\n",
      "âœ… Using existing description for The Frolic tweed boucle cropped jacket co-ord in multi\n",
      "âœ… Using existing description for Topshop Tall faux leather shearling aviator biker jacket in ecru\n",
      "âœ… Using existing description for Topshop mid length tie belted puffer jacket in forest green\n",
      "âœ… Using existing description for Stradivarius STR faux leather fur trim coat in brown\n",
      "âœ… Using existing description for ASOS EDITION hooded trench coat in khaki\n",
      "âœ… Using existing description for Miss Selfridge Petite cropped denim jacket in midwash blue\n",
      "âœ… Using existing description for River Island herringbone duster coat in dark grey\n",
      "âœ… Using existing description for Stradivarius padded puffer jacket in ecru\n",
      "âœ… Using existing description for Weekday Daphne double breasted formal maxi coat in dark grey\n",
      "âœ… Using existing description for ASOS DESIGN Petite cropped rain jacket with hood in black\n",
      "âœ… Using existing description for Only longline formal coat in chocolate\n",
      "âœ… Using existing description for Bershka longline shearling coat in brown\n",
      "âœ… Using existing description for Forever New formal cocoon coat in emerald green\n",
      "âœ… Using existing description for Noisy May Petite longline padded coat with hood in black\n",
      "âœ… Using existing description for Only trench coat in brown check\n",
      "âœ… Using existing description for Topshop Dad denim jacket in bleach\n",
      "âœ… Using existing description for Topshop Tailored double layered funnel neck trench in sage\n",
      "âœ… Using existing description for Vero Moda Tall coated jacket in black\n",
      "âœ… Using existing description for ASOS DESIGN washed premium real leather biker jacket in grey\n",
      "âœ… Using existing description for River Island oversized coat in cream\n",
      "âœ… Using existing description for Topshop Tilda western denim jacket in mid blue\n",
      "âœ… Using existing description for Topshop faux leather trench coat in dark chocolate\n",
      "âœ… Using existing description for NA-KD x Angelica Blick faux leather trench coat in blue\n",
      "âœ… Using existing description for Crooked Tongues x Felix the Cat Unisex varsity jacket in black\n",
      "âœ… Using existing description for Topshop faux leather cropped car coat with faux fur trims in chocolate\n",
      "âœ… Using existing description for Bershka tailored coat in blue\n",
      "âœ… Using existing description for Bershka faux leather racer jacket in blue & white\n",
      "âœ… Using existing description for Selected Femme long line trench coat in beige\n",
      "âœ… Using existing description for Only Tall longline tailored coat in stone\n",
      "âœ… Using existing description for Pull&Bear oversized motorcycle jacket in navy with contrast navy and yellow pannels\n",
      "âœ… Using existing description for Missguided faux leather puffer jacket in white\n",
      "âœ… Using existing description for Reclaimed Vintage longline puffer coat with faux fur detail in black\n",
      "âœ… Using existing description for New Look Tall mid length hooded puffer coat in black\n",
      "âœ… Using existing description for In The Style belted trench coat in beige\n",
      "âœ… Using existing description for Topshop Tall chuck on coat in oat\n",
      "âœ… Using existing description for COLLUSION shaggy faux mongolian fur jacket in cream\n",
      "âœ… Using existing description for Stradivarius tailored belted coat in camel\n",
      "âœ… Using existing description for Stradivarius brushed shacket in ecru\n",
      "âœ… Using existing description for Pimkie double breasted longline coat in brown\n",
      "âœ… Using existing description for ASOS DESIGN longline trench coat in khaki\n",
      "âœ… Using existing description for ASOS DESIGN Petite rubberised rain parka in stone\n",
      "Descriptions generated and saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "import shlex \n",
    "import re\n",
    "\n",
    "# Define LLaVA paths (modify these based on your system)\n",
    "LLAVA_CLI_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/llama-llava-cli\"\n",
    "LLAVA_MODEL_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llava-v1.6-mistral-7b/Mistral-7B-Instruct-v0.2-F32-Q4_K_M.gguf\"\n",
    "MM_PROJ_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/vit/mmproj-model-f16.gguf\"\n",
    "IMAGES_DATA = \"./images_data\"\n",
    "DESCRIPTIONS_DATA = \"./descriptions_data\"\n",
    "\n",
    "# Ensure temp directory exists\n",
    "os.makedirs(IMAGES_DATA, exist_ok=True)\n",
    "os.makedirs(DESCRIPTIONS_DATA, exist_ok=True)\n",
    "\n",
    "def download_image(image_url, filename):\n",
    "    \"\"\"Downloads an image from a URL if it doesn't already exist.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Image already exists: {filename}\")\n",
    "        return filename\n",
    "    \n",
    "    \"\"\"Downloads an image from a URL and saves it locally.\"\"\"\n",
    "    response = requests.get(image_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                file.write(chunk)\n",
    "\n",
    "        print(f\"Downloaded: {filename}\")\n",
    "        return filename\n",
    "    else:\n",
    "        print(f\"Failed to download image: {image_url}\")\n",
    "        return None\n",
    "\n",
    "def extract_description(output_file):\n",
    "    \"\"\"Extracts only the relevant product description from LLaVA output.\"\"\"\n",
    "    with open(output_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find the starting point of the description\n",
    "    start_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"encode_image_with_clip: image encoded\" in line:\n",
    "            start_index = i + 1  # Description starts on the next line\n",
    "            break\n",
    "\n",
    "    # Extract everything after the start_index\n",
    "    if start_index is not None and start_index < len(lines):\n",
    "        return \" \".join(lines[start_index:]).strip()\n",
    "    else:\n",
    "        return \"Description not found\"\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Replaces special characters that are invalid in filenames.\"\"\"\n",
    "    name = name.replace(' ', '_')  # Replace spaces with underscores\n",
    "    return re.sub(r'[\\\\/:\"*?<>|]', '_', name)  # Replace `/ \\ : \" * ? < > |` with `_`\n",
    "\n",
    "def generate_description(image_url, name, color):\n",
    "    \"\"\"Generates a textual description using LLaVA for a given fashion product image.\"\"\"\n",
    "    safe_name = sanitize_filename(name)\n",
    "    image_path = os.path.join(IMAGES_DATA, f\"{safe_name}.jpg\")\n",
    "    description_path = os.path.join(DESCRIPTIONS_DATA, f\"{safe_name}.txt\")\n",
    "\n",
    "    # If description file already exists, read from it\n",
    "    if os.path.exists(description_path):\n",
    "        with open(description_path, \"r\") as file:\n",
    "            existing_description = file.read().strip()\n",
    "\n",
    "        if existing_description and existing_description != \"Description not found\":\n",
    "            print(f\"âœ… Using existing description for {name}\")\n",
    "            return existing_description\n",
    "        else:\n",
    "            print(f\"ðŸ”„ Regenerating description for {name} (previously invalid)\")\n",
    "\n",
    "        # print(f\"Reading existing description for {name}\")\n",
    "        # return open(description_path, \"r\").read()\n",
    "\n",
    "    downloaded_image = download_image(image_url, image_path)\n",
    "    if not downloaded_image:\n",
    "        return \"Image not available\"\n",
    "    \n",
    "    output_file = \"llava_output.txt\"\n",
    "    \n",
    "#     prompt = f\"\"\"{image_path}\n",
    "# USER:\n",
    "# Describe the {color} {name} in this image in detail.\n",
    "# - Focus on its fabric, style, and patterns.\n",
    "# - Ignore other clothing items other than {color} {name} in the image.\n",
    "# - Do NOT add any extra information other than the description.\n",
    "# - Write the response as a single detailed paragraph. Do not use bullet points.\n",
    "# - Avoid listing features separately; instead, describe the product naturally in a flowing sentence.\n",
    "\n",
    "# ASSISTANT:\n",
    "# \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "USER:\n",
    "Describe the {color} {name} in this image in detail.\n",
    "- Focus on its **fabric, style, patterns, and overall aesthetic**.\n",
    "- Mention the **fit** (e.g., loose, tight, relaxed), **comfort level**, and **mobility**.\n",
    "- Describe the **material and texture** (e.g., soft cotton, thick wool, waterproof fabric).\n",
    "- Indicate whether it is **suitable for certain weather conditions** (e.g., breathable for summer, ideal for rainy days).\n",
    "- Suggest occasions it is best suited for (e.g., casual, formal, date night, outdoor wear, business attire).\n",
    "- Optionally mention what it might **pair well with** (e.g., jeans, sneakers, high heels, trench coat).\n",
    "- Ignore other clothing items in the image and focus only on the {color} {name}.\n",
    "- Do NOT add any extra information outside the description.\n",
    "- Write the response as a **single paragraph** with **natural, flowing sentences**.\n",
    "\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    command = f'{LLAVA_CLI_PATH} -m {LLAVA_MODEL_PATH} --mmproj {MM_PROJ_PATH} --image {shlex.quote(image_path)} -c 4096 -p \"{prompt}\" > {output_file}'\n",
    "    print(f\"Running Command: {command}\")  # Debugging\n",
    "    \n",
    "    process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    print(\"STDOUT:\", process.stdout)  # Debugging\n",
    "    print(\"STDERR:\", process.stderr)  # Debugging\n",
    "    \n",
    "    # Extract clean description\n",
    "    description = extract_description(output_file)\n",
    "\n",
    "    # Save the description to a file\n",
    "    with open(description_path, \"w\") as desc_file:\n",
    "        desc_file.write(description)\n",
    "        \n",
    "    print(f\"Generated Description for {name}: {description}\")\n",
    "    return description\n",
    "\n",
    "# Apply LLaVA on limited products\n",
    "df['description'] = df.apply(lambda row: generate_description(row['image link'], row['name'], row['color']), axis=1)\n",
    "df['image_path'] = df.apply(lambda row: os.path.join(IMAGES_DATA, f\"{row['name'].replace(' ', '_')}.jpg\"), axis=1)\n",
    "\n",
    "print(\"Descriptions generated and saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: (takes time)\n",
    "- Generate embedding with MiniLM-L6-v2\n",
    "- Convert embeddings into FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7867\n",
      "Loading existing FAISS index...\n",
      "No new products found. Using existing FAISS index.\n",
      "FAISS index ready & embeddings stored in df!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Directory for FAISS index\n",
    "FAISS_DIR = \"faiss_data\"\n",
    "os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "\n",
    "# File path for FAISS index\n",
    "FAISS_INDEX_FILE = os.path.join(FAISS_DIR, \"faiss_index.bin\")\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 1: Load FAISS index if it exists\n",
    "if os.path.exists(FAISS_INDEX_FILE):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    index = faiss.read_index(FAISS_INDEX_FILE)\n",
    "    num_existing = index.ntotal  # Number of stored products in FAISS\n",
    "\n",
    "    # Retrieve stored embeddings only if FAISS has indexed products\n",
    "    if num_existing > 0:\n",
    "        existing_embeddings = np.zeros((num_existing, index.d), dtype=np.float32)\n",
    "        index.reconstruct_batch(np.arange(num_existing), existing_embeddings)  # Batch retrieval\n",
    "\n",
    "        # Assign stored embeddings back to df\n",
    "        df.loc[df.index[:num_existing], \"embedding\"] = pd.Series(list(existing_embeddings))\n",
    "\n",
    "    # Identify new products that don't have an index yet\n",
    "    new_products = df[df[\"embedding\"].isna()]\n",
    "\n",
    "else:\n",
    "    print(\"Creating new FAISS index...\")\n",
    "    index = None  # Placeholder for FAISS index\n",
    "    new_products = df  # All products are new\n",
    "\n",
    "# Step 2: Generate embeddings ONLY for new products\n",
    "if not new_products.empty:\n",
    "    print(f\"Found {len(new_products)} new products. Updating FAISS index...\")\n",
    "\n",
    "    # ðŸš€ **Batch Encode New Descriptions**\n",
    "    new_embeddings = embedding_model.encode(\n",
    "        new_products[\"description\"].tolist(),\n",
    "        batch_size=32,\n",
    "        convert_to_numpy=True\n",
    "    ).astype(np.float32)  # Ensure correct dtype\n",
    "\n",
    "    new_embeddings = np.array(new_embeddings, dtype=np.float32)\n",
    "\n",
    "    # Store embeddings in df using `.loc`\n",
    "    df.loc[new_products.index, \"embedding\"] = pd.Series(list(new_embeddings), index=new_products.index)\n",
    "\n",
    "\n",
    "    # Convert to FAISS format\n",
    "    new_embeddings_array = np.vstack(df.loc[new_products.index, \"embedding\"].to_numpy())\n",
    "\n",
    "    new_embeddings_array = np.array(new_embeddings_array, dtype=np.float32)\n",
    "\n",
    "    # Add new embeddings to FAISS\n",
    "    if index is None:\n",
    "        index = faiss.IndexFlatL2(new_embeddings_array.shape[1])  # Create FAISS index\n",
    "    index.add(new_embeddings_array)\n",
    "\n",
    "    # Save updated FAISS index\n",
    "    faiss.write_index(index, FAISS_INDEX_FILE)\n",
    "    print(\"FAISS index updated with new products!\")\n",
    "\n",
    "else:\n",
    "    print(\"No new products found. Using existing FAISS index.\")\n",
    "\n",
    "print(\"FAISS index ready & embeddings stored in df!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4:\n",
    "- Retrieve top 3 products with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def retrieve_relevant_products(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Hybrid retrieval: Combines FAISS (dense) and TF-IDF (sparse) for better search.\n",
    "    \"\"\"\n",
    "    #Convert query to FAISS embedding\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True).reshape(1, -1)\n",
    "\n",
    "    #Retrieve from FAISS\n",
    "    top_k_faiss = top_k * 3  # Retrieve more to rerank better\n",
    "    distances, indices = index.search(query_embedding.astype(np.float32), top_k_faiss)\n",
    "    retrieved_products = df.iloc[indices[0]].copy()  # Use .copy() to avoid modifying original df\n",
    "\n",
    "    #Compute cosine similarity for reranking\n",
    "    product_embeddings = np.vstack(retrieved_products[\"embedding\"].to_numpy())\n",
    "    similarity_scores = cosine_similarity(query_embedding, product_embeddings)[0]\n",
    "    retrieved_products[\"similarity\"] = similarity_scores\n",
    "\n",
    "    #Sparse Retrieval Using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[\"name\"] + \" \" + df[\"description\"])  # Use both name & description\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    #Compute TF-IDF similarity scores for retrieved products only\n",
    "    sparse_scores = np.array((tfidf_matrix[retrieved_products.index] @ query_vector.T).todense()).flatten()\n",
    "\n",
    "    #Assign sparse scores only to retrieved products\n",
    "    retrieved_products[\"sparse_score\"] = sparse_scores\n",
    "\n",
    "    # Normalize scores and rerank\n",
    "    retrieved_products[\"final_score\"] = (\n",
    "        0.7 * retrieved_products[\"similarity\"] +  # Dense search weight\n",
    "        0.3 * retrieved_products[\"sparse_score\"]  # Sparse search weight\n",
    "    )\n",
    "    retrieved_products = retrieved_products.sort_values(\"final_score\", ascending=False)\n",
    "\n",
    "    return retrieved_products.head(top_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:\n",
    "- Generate rag text response\n",
    "- Pass in result details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for the \"sequence item 1: expected str instance, list found\" error\n",
    "# Add this to the chat_fashion_assistant function\n",
    "import ollama\n",
    "\n",
    "def generate_rag_response(user_query, criteria=None, session=None):\n",
    "    \"\"\"\n",
    "    Uses Ollama to generate structured product recommendations with explanations.\n",
    "    Fixed to handle list values properly.\n",
    "    \"\"\"\n",
    "    # Prepare the search query with all available criteria\n",
    "    if criteria:\n",
    "        # FIX: Convert any non-string criteria values to strings before joining\n",
    "        criteria_terms = []\n",
    "        for key, value in criteria.items():\n",
    "            if key != \"other\" and value is not None:\n",
    "                # Handle different value types\n",
    "                if isinstance(value, str):\n",
    "                    criteria_terms.append(value)\n",
    "                elif isinstance(value, list):\n",
    "                    # Convert list to string by joining\n",
    "                    criteria_terms.append(\" \".join(str(item) for item in value))\n",
    "                elif isinstance(value, dict):\n",
    "                    # Extract values from dict\n",
    "                    criteria_terms.append(\" \".join(str(item) for item in value.values() if item))\n",
    "                else:\n",
    "                    # Convert other types to string\n",
    "                    criteria_terms.append(str(value))\n",
    "                    \n",
    "        if criteria_terms:\n",
    "            enhanced_query = f\"{' '.join(criteria_terms)} {user_query}\"\n",
    "        else:\n",
    "            enhanced_query = user_query\n",
    "    else:\n",
    "        enhanced_query = user_query\n",
    "        \n",
    "    print(f\"Searching for: {enhanced_query}\")\n",
    "    \n",
    "    # Get relevant products\n",
    "    retrieved_products = retrieve_relevant_products(enhanced_query, top_k=3)\n",
    "\n",
    "    if retrieved_products.empty:\n",
    "        return []\n",
    "\n",
    "    # Create a formatted product list for AI to process\n",
    "    product_list = \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"*Name:* {row['name']}\\n\"\n",
    "            f\"*Description:* {row['description']}\\n\"\n",
    "            f\"*Price:* ${row['price']}\\n\"\n",
    "            f\"*Color:* {row['color']}\\n\"\n",
    "            for i, row in retrieved_products.iterrows()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create conversation context to help with personalization\n",
    "    conversation_context = \"\"\n",
    "    if session and \"conversation_history\" in session:\n",
    "        # Get the last 3 user messages for context\n",
    "        user_messages = [msg[\"content\"] for msg in session[\"conversation_history\"] \n",
    "                        if msg[\"role\"] == \"user\"][-3:]\n",
    "        if user_messages:\n",
    "            conversation_context = \"Recent conversation:\\n\" + \"\\n\".join(user_messages)\n",
    "\n",
    "    # Construct the AI prompt with enhanced context\n",
    "    prompt = f\"\"\"\n",
    "User Query: \"{user_query}\"\n",
    "User Preferences: {str(criteria) if criteria else 'Not specified'}\n",
    "{conversation_context}\n",
    "\n",
    "The following fashion products were retrieved as the most relevant matches:\n",
    "\n",
    "{product_list}\n",
    "\n",
    "Act as a fashion AI assistant. For each product:\n",
    "1. Explain why it matches the user's preferences and query\n",
    "2. Highlight key features that make it suitable for their needs\n",
    "3. Provide 1-2 brief styling tips or suggestions\n",
    "4. If appropriate, mention occasions where this would work well\n",
    "\n",
    "Be conversational and personalized. Respond with a brief paragraph (3-5 sentences max) for each product.\n",
    "Don't start with phrases like \"This product...\" or \"Here we have...\".\n",
    "Don't repeat the product name verbatim.\n",
    "\"\"\"\n",
    "\n",
    "    # Generate response with Ollama\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        response_text = response[\"message\"][\"content\"]\n",
    "\n",
    "        # Split the AI response into separate product explanations\n",
    "        explanations = response_text.split(\"\\n\\n\")  # Splitting paragraphs for individual products\n",
    "        \n",
    "        # Format structured output for the chat\n",
    "        structured_recommendations = []\n",
    "        for (index, row), explanation in zip(retrieved_products.iterrows(), explanations[:len(retrieved_products)]):\n",
    "            # Clean up the explanation - remove product name if it appears at the start\n",
    "            clean_explanation = explanation.strip()\n",
    "            product_name_lower = str(row['name']).lower()\n",
    "            \n",
    "            # If explanation starts with the product name, remove it\n",
    "            if clean_explanation.lower().startswith(product_name_lower[:20]):\n",
    "                clean_explanation = clean_explanation[len(product_name_lower):].strip()\n",
    "            \n",
    "            # Format the product card with emoji for visual appeal\n",
    "            structured_recommendations.append(\n",
    "                {\n",
    "                    \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{clean_explanation}\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "                    \"image\": row[\"image link\"],\n",
    "                    \"images\": row[\"images\"]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return structured_recommendations  # Return structured list of text + images\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating recommendations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Fallback without Ollama explanations\n",
    "        structured_recommendations = []\n",
    "        for index, row in retrieved_products.iterrows():\n",
    "            structured_recommendations.append(\n",
    "                {\n",
    "                    \"text\": f\"**{row['name']}**\\n\\nðŸ’° **${row['price']}** | ðŸŽ¨ {row['color']}\\n\\n{row['description'][:150]}...\\n\\nðŸ”— [View Product]({row['url']})\",\n",
    "                    \"image\": row[\"image link\"],\n",
    "                    \"images\": row[\"images\"]\n",
    "                }\n",
    "            )\n",
    "        return structured_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: \n",
    "- Chat function for Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# def chat_fashion_assistant(user_input, history):\n",
    "#     \"\"\"\n",
    "#     Processes user query and returns structured product recommendations with AI-generated explanations.\n",
    "#     \"\"\"\n",
    "#     #Get AI-generated recommendations\n",
    "#     recommendations = generate_rag_response(user_input)\n",
    "\n",
    "#     if not recommendations:\n",
    "#         return [{\"role\": \"assistant\", \"content\": \"No matching products found.\"}]\n",
    "\n",
    "#     #Create structured response list\n",
    "#     response_list = []\n",
    "#     for rec in recommendations:\n",
    "#         images = ast.literal_eval(rec[\"images\"])\n",
    "        \n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # AI explanation\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "#                                                                         columns=4, \n",
    "#                                                                         rows=1, \n",
    "#                                                                         object_fit=\"cover\", \n",
    "#                                                                         height=\"automatic\",\n",
    "#                                                                         allow_preview=True)\n",
    "#                                                                         }) \n",
    "\n",
    "#         response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds a horizontal divider and spacing\n",
    "\n",
    "#         # response_list.append(gr.Image(rec[\"image\"]))  # Product image\n",
    "\n",
    "#     return response_list  #Returning structured chat messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_with_llava(image_path, user_query=None):\n",
    "    \"\"\"\n",
    "    Uses LLaVA to generate a description of the clothing item in the image,\n",
    "    letting LLaVA itself deduce the target item from the user's query.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the uploaded image\n",
    "        user_query (str, optional): The user's text query to focus the analysis\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (description, keywords) - The focused description and extracted keywords\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import shlex\n",
    "    import re\n",
    "    import tempfile\n",
    "    \n",
    "    print(f\"[DEBUG] Starting image analysis for: {image_path}\")\n",
    "    if user_query:\n",
    "        print(f\"[DEBUG] Query-aware analysis with: '{user_query}'\")\n",
    "    \n",
    "    # Use the exact same LLaVA paths as in Step 2\n",
    "    LLAVA_CLI_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/llama-llava-cli\"\n",
    "    LLAVA_MODEL_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llava-v1.6-mistral-7b/Mistral-7B-Instruct-v0.2-F32-Q4_K_M.gguf\"\n",
    "    MM_PROJ_PATH = \"/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/vit/mmproj-model-f16.gguf\"\n",
    "    \n",
    "    # Temporary file for LLaVA output\n",
    "    output_file = os.path.join(tempfile.gettempdir(), \"llava_output.txt\")\n",
    "    print(f\"[DEBUG] LLaVA output will be saved to: {output_file}\")\n",
    "    \n",
    "    # Craft a prompt based on whether we have a user query\n",
    "    if user_query:\n",
    "        # Let LLaVA figure out what item to focus on from the query\n",
    "        prompt = f\"\"\"\n",
    "        \n",
    "USER: {user_query}\n",
    "\n",
    "Analyze this image and:\n",
    "1. Identify the fashion item the user is most likely referring to in their request\n",
    "2. Describe that specific item in detail, focusing on:\n",
    "   - Style, design, and unique features \n",
    "   - Color and pattern details\n",
    "   - Material and texture appearance\n",
    "   - Fit and silhouette\n",
    "   - Any distinctive elements or embellishments\n",
    "\n",
    "Ignore other clothing items or accessories unless they're related to my request.\n",
    "\n",
    "End your response with 5-7 keywords that best describe this item, based on your description, formatted as:\n",
    "KEYWORDS: keyword1, keyword2, keyword3, etc.\n",
    "\n",
    "ASSISTANT:\n",
    "\"\"\"\n",
    "    else:\n",
    "        # Generic clothing description if no specific item was mentioned\n",
    "        prompt = f\"\"\"\n",
    "USER:\n",
    "Describe the most prominent clothing item in this image in detail. Focus on:\n",
    "- Identify the main garment (e.g., jacket, dress, pants)\n",
    "- Style, design, and unique features\n",
    "- Color and pattern details\n",
    "- Material and texture appearance\n",
    "- Fit and silhouette\n",
    "- Any distinctive elements or embellishments\n",
    "\n",
    "Then provide a list of 5-7 keywords that best describe this item, prefixed with \"KEYWORDS:\".\n",
    "\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "    # Run LLaVA command\n",
    "    try:\n",
    "        command = f'{LLAVA_CLI_PATH} -m {LLAVA_MODEL_PATH} --mmproj {MM_PROJ_PATH} --image {shlex.quote(image_path)} -c 4096 -p \"{prompt}\" > {output_file}'\n",
    "        print(f\"[DEBUG] Executing LLaVA command\")\n",
    "        print(command)\n",
    "        process = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        \n",
    "        # Check if the command succeeded\n",
    "        if process.returncode != 0:\n",
    "            print(f\"[ERROR] LLaVA command failed with return code {process.returncode}\")\n",
    "            print(f\"[ERROR] stderr: {process.stderr}\")\n",
    "            return \"A clothing item\", [\"clothing\"]\n",
    "        \n",
    "        print(f\"[DEBUG] LLaVA command completed successfully\")\n",
    "        \n",
    "        # Read the output file\n",
    "        with open(output_file, 'r') as f:\n",
    "            output_text = f.read()\n",
    "            \n",
    "        print(f\"[DEBUG] LLaVA output file size: {len(output_text)} characters\")\n",
    "        \n",
    "        # Extract the description part\n",
    "        description_lines = []\n",
    "        capture = False\n",
    "        \n",
    "        for line in output_text.split('\\n'):\n",
    "            if 'encode_image_with_clip: image encoded' in line:\n",
    "                capture = True\n",
    "                print(f\"[DEBUG] Found marker line for description start\")\n",
    "                continue\n",
    "            \n",
    "            if capture and not line.startswith('['):\n",
    "                description_lines.append(line)\n",
    "        \n",
    "        description = ' '.join(description_lines).strip()\n",
    "        print(f\"[DEBUG] Extracted description ({len(description)} chars): {description[:100]}...\")\n",
    "        \n",
    "        # Extract keywords from the description\n",
    "        keywords = []\n",
    "        if \"KEYWORDS:\" in description:\n",
    "            print(f\"[DEBUG] Found KEYWORDS section in output\")\n",
    "            # Get the part after \"KEYWORDS:\"\n",
    "            keyword_section = description.split(\"KEYWORDS:\")[1].strip()\n",
    "            # Split by commas or spaces if no commas\n",
    "            if \",\" in keyword_section:\n",
    "                keywords = [k.strip().lower() for k in keyword_section.split(\",\")]\n",
    "            else:\n",
    "                keywords = re.findall(r'\\b[A-Za-z]+\\b', keyword_section.lower())\n",
    "            \n",
    "            # Clean up the description to remove the keywords section\n",
    "            description = description.split(\"KEYWORDS:\")[0].strip()\n",
    "            print(f\"[DEBUG] Successfully extracted {len(keywords)} keywords: {keywords}\")\n",
    "\n",
    "        # Fallback method\n",
    "        else:\n",
    "            print(f\"[DEBUG] No KEYWORDS section found, extracting from description\")\n",
    "            # If no keywords section, extract important words from description\n",
    "            clothing_terms = [\"dress\", \"jacket\", \"shirt\", \"pants\", \"coat\", \"blouse\", \"sweater\", \n",
    "                             \"jeans\", \"skirt\", \"hoodie\", \"blazer\", \"suit\", \"top\", \"shorts\"]\n",
    "            color_terms = [\"black\", \"white\", \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \n",
    "                          \"pink\", \"orange\", \"grey\", \"gray\", \"brown\", \"navy\", \"beige\"]\n",
    "            style_terms = [\"casual\", \"formal\", \"elegant\", \"vintage\", \"modern\", \"classic\", \n",
    "                          \"sporty\", \"bohemian\", \"minimalist\", \"business\", \"trendy\"]\n",
    "            \n",
    "            # Look for these terms in the description\n",
    "            words = re.findall(r'\\b[A-Za-z]+\\b', description.lower())\n",
    "            for word in words:\n",
    "                if (word in clothing_terms or word in color_terms or word in style_terms) and word not in keywords:\n",
    "                    keywords.append(word)\n",
    "                    \n",
    "            # Limit to most relevant keywords\n",
    "            keywords = keywords[:7]\n",
    "            print(f\"[DEBUG] Extracted {len(keywords)} keywords from description: {keywords}\")\n",
    "        \n",
    "        # If we couldn't extract a good description or keywords, provide a fallback\n",
    "        if not description or len(description) < 20:\n",
    "            print(f\"[DEBUG] Description too short, using fallback\")\n",
    "            return \"A clothing item\", [\"clothing\"]\n",
    "            \n",
    "        print(f\"[DEBUG] LLaVA analysis completed successfully âœ…\")\n",
    "        return description, keywords\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Exception during image analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Provide a fallback in case of error\n",
    "        return \"A clothing item\", [\"clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track conversation state\n",
    "user_sessions = defaultdict(lambda: {\n",
    "    \"conversation_history\": [],\n",
    "    \"criteria_collected\": {},\n",
    "    \"stage\": \"initial\",\n",
    "    \"recommendations_shown\": False,\n",
    "    \"image_analysis\": None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_fashion_assistant(user_input, image=None, history=None, session_id=\"default\"):\n",
    "    \"\"\"\n",
    "    AI-powered conversational shopping assistant with improved error handling.\n",
    "    \n",
    "    Args:\n",
    "        user_input (str): The user's text message\n",
    "        image (Image, optional): Uploaded image for visual search. Defaults to None.\n",
    "        history (list, optional): Chat history. Defaults to None.\n",
    "        session_id (str, optional): Unique session identifier. Defaults to \"default\".\n",
    "    \n",
    "    Returns:\n",
    "        list: List of response messages\n",
    "    \"\"\"\n",
    "    # Initialize history if None\n",
    "    if history is None:\n",
    "        history = []\n",
    "    \n",
    "    # Get or create session\n",
    "    session = user_sessions[session_id]\n",
    "    \n",
    "    # Handle special restart requests\n",
    "    restart_phrases = [\"start over\", \"restart\", \"reset\", \"new search\", \"start again\"]\n",
    "    if user_input and any(phrase in user_input.lower() for phrase in restart_phrases):\n",
    "        # Reset the session\n",
    "        session[\"criteria_collected\"] = {}\n",
    "        session[\"stage\"] = \"initial\"\n",
    "        session[\"recommendations_shown\"] = False\n",
    "        session[\"conversation_history\"] = []\n",
    "        session[\"image_analysis\"] = None\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "    # Handle empty inputs gracefully\n",
    "    if not user_input.strip() and image is None:\n",
    "        # If there's truly no input, provide a greeting/help message\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Hi there! I can help you find clothing items. What are you looking for today? You can also upload an image if you have something specific in mind.\"}]\n",
    "    \n",
    "    # Handle image upload if present\n",
    "    search_query = user_input if user_input else \"\"\n",
    "    image_description = None\n",
    "    \n",
    "    if image is not None:\n",
    "        try:\n",
    "            # Process the image\n",
    "            import os\n",
    "            import tempfile\n",
    "            from PIL import Image as PILImage\n",
    "            \n",
    "            print(f\"[DEBUG] Image detected in chat input\")\n",
    "            \n",
    "            # Save the uploaded image to a temporary file if needed\n",
    "            # REDUNDANT\n",
    "            if isinstance(image, str) and os.path.exists(image):\n",
    "                image_path = image\n",
    "                print(f\"[DEBUG] Using existing image path: {image_path}\")\n",
    "            else:\n",
    "                # Handle PIL Image or other image types\n",
    "                temp_dir = tempfile.gettempdir()\n",
    "                temp_img_path = os.path.join(temp_dir, f\"upload_{os.urandom(4).hex()}.jpg\")\n",
    "                \n",
    "                if hasattr(image, 'save'):  # PIL Image\n",
    "                    image.save(temp_img_path)\n",
    "                    image_path = temp_img_path\n",
    "                    print(f\"[DEBUG] Saved PIL image to: {image_path}\")\n",
    "                else:\n",
    "                    print(f\"[DEBUG] Unsupported image type: {type(image)}\")\n",
    "                    image_path = None\n",
    "            \n",
    "            if image_path and os.path.exists(image_path):\n",
    "                print(f\"[DEBUG] Calling analyze_image_with_llava with path: {image_path}\")\n",
    "                # Call the analyze_image_with_llava function\n",
    "                image_description, keywords = analyze_image_with_llava(image_path, user_input)\n",
    "                \n",
    "                print(f\"[DEBUG] Image analysis complete. Description: {image_description[:50]}...\")\n",
    "                print(f\"[DEBUG] Extracted keywords: {keywords}\")\n",
    "                \n",
    "                # Store in session\n",
    "                session[\"image_analysis\"] = {\n",
    "                    \"description\": image_description,\n",
    "                    \"keywords\": keywords,\n",
    "                    \"image_path\": image_path\n",
    "                }\n",
    "                \n",
    "                # Enhance the search query with keywords\n",
    "                if keywords:\n",
    "                    keyword_str = \" \".join(keywords)\n",
    "                    if search_query:\n",
    "                        search_query = f\"{search_query} {keyword_str}\"\n",
    "                    else:\n",
    "                        search_query = keyword_str\n",
    "                    print(f\"[DEBUG] Enhanced search query: {search_query}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Exception during image processing: {e}\")\n",
    "            # Continue without image analysis\n",
    "    \n",
    "    # Add user message to conversation history\n",
    "    # IMPORTANT: Make sure we're storing the exact message that was input, not a modified version\n",
    "    # This ensures different messages remain separate\n",
    "    session[\"conversation_history\"].append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # If we have image analysis, acknowledge it\n",
    "    if image is not None and image_description:\n",
    "        # Add initial response about the image\n",
    "        image_response = {\"role\": \"assistant\", \"content\": f\"I can see the item in your image. It looks like {image_description[:100]}...\"}\n",
    "        \n",
    "        # If there's no text query, ask for more details and return\n",
    "        if not user_input.strip():\n",
    "            session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": image_response[\"content\"]})\n",
    "            return [image_response, {\"role\": \"assistant\", \"content\": \"Is there anything specific about this item you're looking for? Or shall I find similar products?\"}]\n",
    "    \n",
    "    # Have AI analyze the message and context\n",
    "    try:\n",
    "        # Create a context-aware prompt for the AI\n",
    "        prompt = f\"\"\"\n",
    "        You are a fashion shopping assistant. Analyze the user's message and conversation context, then respond with a JSON object only.\n",
    "\n",
    "        CONVERSATION CONTEXT:\n",
    "        - Previous messages: {json.dumps(session[\"conversation_history\"][:-1])[:1000] if len(session[\"conversation_history\"]) > 1 else \"This is the start of the conversation.\"}\n",
    "        - Current criteria: {json.dumps(session[\"criteria_collected\"])}\n",
    "        - Current stage: {session[\"stage\"]}\n",
    "        - Recommendations shown: {\"Yes\" if session[\"recommendations_shown\"] else \"No\"}\n",
    "        - Image info: {json.dumps(session[\"image_analysis\"]) if session.get(\"image_analysis\") else \"None\"}\n",
    "        - Latest message: \"{user_input}\"\n",
    "\n",
    "        INSTRUCTIONS:\n",
    "        Must return a JSON object with these fields:\n",
    "        - extracted_criteria: Object containing clothing criteria detected in the conversation with confidence levels\n",
    "        - action: String value (one of the defined actions below)\n",
    "        - missing_criterion: String indicating what information to ask for next (if needed)\n",
    "        - question: String with a suggested follow-up question (if applicable)\n",
    "        - search_query: String with optimized search terms based on criteria\n",
    "\n",
    "        ACTIONS:\n",
    "        - \"greet\": When the user is starting a conversation or greeting\n",
    "        - \"ask_for_criteria\": When we need more information before searching (must set missing_criterion)\n",
    "        - \"search_products\": When the user explicitly asks to see products OR we have sufficient criteria\n",
    "        - \"show_more\": When the user wants more options similar to previously shown products\n",
    "        - \"restart\": When the user explicitly requests to start over\n",
    "        - \"answer_question\": When the user asks a question related to fashion or products\n",
    "\n",
    "        IMPORTANT FORMATTING REQUIREMENTS:\n",
    "        - For action \"greet\", set extracted_criteria to null\n",
    "        - For all other actions, \"extracted_criteria\" must include the relevant criteria.\n",
    "        - Use null for ANY criteria not explicitly mentioned by the user\n",
    "        - Ensure the JSON is properly formatted with all required fields\n",
    "\n",
    "        SPECIAL INSTRUCTIONS FOR \"GREET\" ACTION:\n",
    "        When setting action to \"greet\", the \"question\" field must be a comprehensive onboarding question that asks for ALL of the user's preferences at once. Make sure each question is separated into its own line:\n",
    "        1. Occasion (business meeting, birthday party, music festival, etc.)\n",
    "        2. Type of fashion item (jackets, shoes, hats, etc.)\n",
    "        3. Color preferences (blue, pink, patterns, etc.)\n",
    "        4. Price range (<$50, $50-$100, >$100, etc.)\n",
    "\n",
    "        The question should be concise but cover all four attributes in a single message.\n",
    "\n",
    "        EXAMPLE OUTPUTS:\n",
    "\n",
    "        1. For a greeting:\n",
    "        ```\n",
    "        {{\n",
    "        \"extracted_criteria\": null,\n",
    "        \"action\": \"greet\",\n",
    "        \"missing_criterion\": \"item_type\",\n",
    "        \"question\": \"Welcome to ShopGPT! To help you find the perfect outfit, please tell me: \\n 1) What occasion is this for (business, casual, party)? \\n 2) What type of clothing item (jacket, dress, shoes)? \\n 3) Any color preferences? \\n 4) Your price range (<$50, $50-$100, >$100)?\",\n",
    "        \"search_query\": \"\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        2. For a product search:\n",
    "        ```\n",
    "        {{\n",
    "        \"extracted_criteria\": {{\n",
    "            \"item_type\": \"jacket\",\n",
    "            \"style\": \"casual\",\n",
    "            \"color\": \"blue\",\n",
    "            \"occasion\": null,\n",
    "            \"price_range\": null,\n",
    "            \"other\": null\n",
    "        }},\n",
    "        \"action\": \"search_products\",\n",
    "        \"missing_criterion\": null,\n",
    "        \"question\": null,\n",
    "        \"search_query\": \"blue casual jacket\"\n",
    "        }}\n",
    "        ```\n",
    "\n",
    "        IMPORTANT NOTES:\n",
    "        - For \"search_query\": Construct from all available criteria; prioritize user's explicit terms. Also integrate this {search_query}.\n",
    "        - For \"ask_for_criteria\": Focus on the most important missing information\n",
    "        - For \"search_products\": Use when user directly asks for products OR when crucial criteria are known\n",
    "        - For \"show_more\": Use when user indicates they want more similar products to what was shown\n",
    "        \"\"\"\n",
    "\n",
    "        # Send to Ollama for analysis\n",
    "        response = ollama.chat(\n",
    "            model=\"mistral\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        print(response)\n",
    "        # Parse the JSON response\n",
    "        analysis_text = response[\"message\"][\"content\"]\n",
    "        # Find the JSON part in case there's additional text\n",
    "        json_start = analysis_text.find('{')\n",
    "        json_end = analysis_text.rfind('}') + 1\n",
    "        \n",
    "        if json_start >= 0 and json_end > json_start:\n",
    "            json_part = analysis_text[json_start:json_end]\n",
    "            analysis = json.loads(json_part)\n",
    "        else:\n",
    "            # Fallback if JSON parsing fails\n",
    "            raise ValueError(\"Could not extract valid JSON from the response\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error analyzing message: {e}\")\n",
    "        # Fallback analysis if there's an error\n",
    "        analysis = {\n",
    "            \"extracted_criteria\": {},\n",
    "            \"action\": \"search_products\" if \"show me\" in user_input.lower() or image is not None else \"ask_for_criteria\",\n",
    "            \"missing_criterion\": \"item_type\",\n",
    "            \"question\": \"What type of clothing are you looking for?\",\n",
    "            \"understanding\": \"I'm trying to understand what you're looking for.\",\n",
    "            \"ready_to_search\": False,\n",
    "            \"search_query\": search_query\n",
    "        }\n",
    "    \n",
    "    # Update session with extracted criteria - FIX THE ERROR HERE\n",
    "    if analysis[\"extracted_criteria\"] is not None:\n",
    "        for criterion, value in analysis[\"extracted_criteria\"].items():\n",
    "            if value:  # Just check if value exists\n",
    "                # Check type to prevent errors\n",
    "                if isinstance(value, str) and value.lower() not in (\"null\", \"none\"):\n",
    "                    session[\"criteria_collected\"][criterion] = value\n",
    "                elif isinstance(value, (list, dict)):\n",
    "                    # Handle complex value types properly\n",
    "                    session[\"criteria_collected\"][criterion] = value\n",
    "                # Skip None values and empty strings\n",
    "    \n",
    "    # Handle different conversation actions\n",
    "\n",
    "    # GREET: ONBOARDING\n",
    "    if analysis[\"action\"] == \"greet\":\n",
    "        session[\"stage\"] = \"collecting\"\n",
    "        return [{\"role\": \"assistant\", \"content\": f\"Hi! I'd be happy to help you find the perfect outfit. You can describe what you're looking for or upload an image. {analysis.get('question', 'What type of clothing are you looking for today?')}\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"ask_for_criteria\":\n",
    "        session[\"stage\"] = \"collecting\"\n",
    "        question = analysis.get(\"question\") or f\"Can you tell me what kind of {analysis.get('missing_criterion', 'item')} you're looking for?\"\n",
    "        return [{\"role\": \"assistant\", \"content\": question}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"search_products\" or analysis[\"action\"] == \"show_more\":\n",
    "        session[\"stage\"] = \"searching\"\n",
    "        # Use the existing retrieve_relevant_products and generate_rag_response functions\n",
    "        search_query = analysis.get(\"search_query\") or search_query\n",
    "        \n",
    "        # If we have image analysis, incorporate it into the search (if not already in search_query)\n",
    "        if session.get(\"image_analysis\") and session[\"image_analysis\"].get(\"keywords\"):\n",
    "            # Check if keywords are already in the query\n",
    "            keyword_present = False\n",
    "            for keyword in session[\"image_analysis\"][\"keywords\"]:\n",
    "                if keyword.lower() in search_query.lower():\n",
    "                    keyword_present = True\n",
    "                    break\n",
    "            \n",
    "            if not keyword_present:\n",
    "                keyword_str = \" \".join(session[\"image_analysis\"][\"keywords\"])\n",
    "                search_query = f\"{search_query} {keyword_str}\"\n",
    "                print(f\"[DEBUG] Added image keywords to search query: {search_query}\")\n",
    "        \n",
    "        # Get AI-generated recommendations\n",
    "        print(f\"[DEBUG] Calling generate_rag_response with query: {search_query}\")\n",
    "        try:\n",
    "            recommendations = generate_rag_response(search_query, session[\"criteria_collected\"], session)\n",
    "            \n",
    "            if not recommendations:\n",
    "                # No products found - ask if user wants to broaden search\n",
    "                # future expansion - API Calls\n",
    "                session[\"recommendations_shown\"] = True\n",
    "                return [{\"role\": \"assistant\", \"content\": \"I couldn't find any products matching your criteria. Could you be more general or try different options?\"}]\n",
    "            \n",
    "            # Create structured response list\n",
    "            response_list = []\n",
    "            \n",
    "            # First, summarize what we understood from their requirements\n",
    "            # need to get actual criterias - TO FIX\n",
    "            criteria_display = {\n",
    "                \"item_type\": \"Item\", \n",
    "                \"style\": \"Style\", \n",
    "                \"color\": \"Color\", \n",
    "                \"occasion\": \"Occasion\", \n",
    "                \"price_range\": \"Price\",\n",
    "                \"other\": \"Other\"\n",
    "            }\n",
    "            \n",
    "            criteria_summary = \", \".join([f\"{criteria_display[k]}: {v}\" for k, v in session[\"criteria_collected\"].items() \n",
    "                                        if v and k in criteria_display])\n",
    "            \n",
    "            # If we have image analysis, mention it\n",
    "            if session.get(\"image_analysis\"):\n",
    "                if criteria_summary:\n",
    "                    response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image and preferences ({criteria_summary}), here are some recommendations:\"})\n",
    "                else:\n",
    "                    response_list.append({\"role\": \"assistant\", \"content\": f\"Based on your image, here are some similar products:\"})\n",
    "            elif criteria_summary:\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": f\"Here are some recommendations based on your preferences ({criteria_summary}):\"})\n",
    "            else:\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": \"Here are some recommendations based on your request:\"})\n",
    "            \n",
    "            # Add products with images and descriptions\n",
    "            for rec in recommendations:\n",
    "                try:\n",
    "                    images = ast.literal_eval(rec[\"images\"])\n",
    "                except:\n",
    "                    # Fallback if images can't be parsed\n",
    "                    images = [rec[\"image\"]]\n",
    "                \n",
    "                response_list.append({\"role\": \"assistant\", \"content\": rec[\"text\"]})  # Product with AI explanation\n",
    "                response_list.append({\"role\": \"assistant\", \"content\": gr.Gallery(images[:4], \n",
    "                                                                            columns=4, \n",
    "                                                                            rows=1, \n",
    "                                                                            object_fit=\"cover\", \n",
    "                                                                            height=\"automatic\",\n",
    "                                                                            allow_preview=True)\n",
    "                                                                            }) \n",
    "            \n",
    "                response_list.append({\"role\": \"assistant\", \"content\": \"\\n\\n\\n\\n\\n\\n\"})  # Adds spacing\n",
    "            \n",
    "            # Add follow-up prompt\n",
    "            response_list.append({\"role\": \"assistant\", \"content\": \"Would you like to see more options, or should I help you find something else?\"})\n",
    "            \n",
    "            # Update session\n",
    "            session[\"recommendations_shown\"] = True\n",
    "            session[\"stage\"] = \"recommending\"\n",
    "            \n",
    "            # Add assistant response to conversation history\n",
    "            session[\"conversation_history\"].append({\"role\": \"assistant\", \"content\": \"I showed some product recommendations based on the user's criteria.\"})\n",
    "            \n",
    "            return response_list\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Exception during recommendation generation: {e}\")\n",
    "            # Provide a fallback response\n",
    "            return [{\"role\": \"assistant\", \"content\": \"I'm sorry, I encountered an error while searching for products. Could you try a different query?\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"restart\":\n",
    "        # Reset the session (redundant with the check at the beginning, but keeping for completeness)\n",
    "        session[\"criteria_collected\"] = {}\n",
    "        session[\"stage\"] = \"collecting\" \n",
    "        session[\"recommendations_shown\"] = False\n",
    "        session[\"conversation_history\"] = []\n",
    "        session[\"image_analysis\"] = None\n",
    "        return [{\"role\": \"assistant\", \"content\": \"Let's start fresh! What are you looking for today? You can describe it or upload an image.\"}]\n",
    "    \n",
    "    elif analysis[\"action\"] == \"answer_question\":\n",
    "        # If the AI detects a question not related to product search\n",
    "        if \"question\" in analysis and analysis[\"question\"]:\n",
    "            return [{\"role\": \"assistant\", \"content\": analysis[\"question\"]}]\n",
    "        else:\n",
    "            return [{\"role\": \"assistant\", \"content\": \"I'm here to help you find fashion products. What kind of item are you looking for?\"}]\n",
    "    \n",
    "    # Default fallback response if analysis doesn't yield actionable results\n",
    "    return [{\"role\": \"assistant\", \"content\": \"I'm not sure I understood. Could you tell me what kind of clothing or fashion item you're looking for? You can also upload an image if you have one.\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: \n",
    "- Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/ipykernel_61537/1768555090.py:12: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/ipykernel_61537/1768555090.py:12: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://e7229ac05c8ec64ae4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e7229ac05c8ec64ae4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 691,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='mistral' created_at='2025-03-14T23:53:55.128735Z' done=True done_reason='stop' total_duration=13131730958 load_duration=19220208 prompt_eval_count=971 prompt_eval_duration=7045000000 eval_count=154 eval_duration=6062000000 message=Message(role='assistant', content=' ```\\n   {\\n       \"extracted_criteria\": null,\\n       \"action\": \"greet\",\\n       \"missing_criterion\": \"item_type,occasion,color,price_range\",\\n       \"question\": \"Welcome to ShopGPT! To help you find the perfect outfit, please tell me:\\\\n1) What occasion is this for (business, casual, party)?\\\\n2) What type of clothing item (jacket, dress, shoes)?\\\\n3) Any color preferences?\\\\n4) Your price range (<$50, $50-$100, >$100)?\",\\n       \"search_query\": \"\"\\n   }\\n   ```', images=None, tool_calls=None)\n",
      "model='mistral' created_at='2025-03-14T23:55:05.30099Z' done=True done_reason='stop' total_duration=10354475959 load_duration=23228334 prompt_eval_count=1027 prompt_eval_duration=5780000000 eval_count=127 eval_duration=4548000000 message=Message(role='assistant', content=' {\\n       \"extracted_criteria\": {\\n           \"item_type\": \"jacket\",\\n           \"color\": \"bright\",\\n           \"occasion\": \"music festival\",\\n           \"price_range\": \"<100\",\\n           \"other\": null\\n       },\\n       \"action\": \"ask_for_criterion\",\\n       \"missing_criterion\": \"style\",\\n       \"question\": \"Is there a specific style you prefer for the jacket? (ex. denim, leather, bomber)\",\\n       \"search_query\": \"\"\\n   }', images=None, tool_calls=None)\n",
      "[DEBUG] Image detected in chat input\n",
      "[DEBUG] Saved PIL image to: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_c51b4b49.jpg\n",
      "[DEBUG] Calling analyze_image_with_llava with path: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_c51b4b49.jpg\n",
      "[DEBUG] Starting image analysis for: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_c51b4b49.jpg\n",
      "[DEBUG] Query-aware analysis with: 'I want a jacket like this'\n",
      "[DEBUG] LLaVA output will be saved to: /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/llava_output.txt\n",
      "[DEBUG] Executing LLaVA command\n",
      "/Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/llama-llava-cli -m /Users/glennsuristio/Documents/Projects/dressAI/llava-v1.6-mistral-7b/Mistral-7B-Instruct-v0.2-F32-Q4_K_M.gguf --mmproj /Users/glennsuristio/Documents/Projects/dressAI/llama.cpp/vit/mmproj-model-f16.gguf --image /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/upload_c51b4b49.jpg -c 4096 -p \"\n",
      "\n",
      "USER: I want a jacket like this\n",
      "\n",
      "Analyze this image and:\n",
      "1. Identify the fashion item the user is most likely referring to in their request\n",
      "2. Describe that specific item in detail, focusing on:\n",
      "   - Style, design, and unique features \n",
      "   - Color and pattern details\n",
      "   - Material and texture appearance\n",
      "   - Fit and silhouette\n",
      "   - Any distinctive elements or embellishments\n",
      "\n",
      "Ignore other clothing items or accessories unless they're related to my request.\n",
      "\n",
      "End your response with 5-7 keywords that best describe this item, based on your description, formatted as:\n",
      "KEYWORDS: keyword1, keyword2, keyword3, etc.\n",
      "\n",
      "ASSISTANT:\n",
      "\" > /var/folders/rj/sysxzl8x0q1dxp5rrjfyq19m0000gn/T/llava_output.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] LLaVA command completed successfully\n",
      "[DEBUG] LLaVA output file size: 4802 characters\n",
      "[DEBUG] Found marker line for description start\n",
      "[DEBUG] Extracted description (1089 chars): The user is most likely referring to the pink jacket the person in the image is wearing.  1. The pin...\n",
      "[DEBUG] Found KEYWORDS section in output\n",
      "[DEBUG] Successfully extracted 1 keywords: ['zip']\n",
      "[DEBUG] LLaVA analysis completed successfully âœ…\n",
      "[DEBUG] Image analysis complete. Description: The user is most likely referring to the pink jack...\n",
      "[DEBUG] Extracted keywords: ['zip']\n",
      "[DEBUG] Enhanced search query: I want a jacket like this zip\n",
      "model='mistral' created_at='2025-03-14T23:57:19.455145Z' done=True done_reason='stop' total_duration=15261956292 load_duration=23217709 prompt_eval_count=1367 prompt_eval_duration=10515000000 eval_count=131 eval_duration=4720000000 message=Message(role='assistant', content=' {\\n    \"extracted_criteria\": {\\n        \"item_type\": \"jacket\",\\n        \"color\": \"bright\",\\n        \"occasion\": \"music festival\",\\n        \"price_range\": \"<100\",\\n        \"other\": {\"zip\": true}\\n    },\\n    \"action\": \"search_products\",\\n    \"missing_criterion\": null,\\n    \"question\": null,\\n    \"search_query\": \"bright colored jacket for music festival under 100 dollars with zip (similar to the one in the image)\"\\n   }', images=None, tool_calls=None)\n",
      "[DEBUG] Calling generate_rag_response with query: bright colored jacket for music festival under 100 dollars with zip (similar to the one in the image)\n",
      "Searching for: jacket bright music festival <100 bright colored jacket for music festival under 100 dollars with zip (similar to the one in the image)\n"
     ]
    }
   ],
   "source": [
    "def create_fashion_interface():\n",
    "    import gradio as gr\n",
    "    \"\"\"\n",
    "    Creates a ShopGPT interface with actual image previews\n",
    "    in both the input area and chat.\n",
    "    \"\"\"\n",
    "    with gr.Blocks(theme='allenai/gradio-theme') as app:\n",
    "        gr.Markdown(\"# ðŸ›ï¸ ShopGPT\")\n",
    "        gr.Markdown(\"I'll help you find the perfect outfit! Describe what you're looking for or upload an image.\")\n",
    "        \n",
    "        # Chatbot component\n",
    "        chatbot = gr.Chatbot(\n",
    "            height=600,\n",
    "            show_copy_button=False,\n",
    "            bubble_full_width=False,\n",
    "        )\n",
    "        \n",
    "        # Loading indicator\n",
    "        with gr.Row(visible=False) as loading_indicator:\n",
    "            gr.Markdown(\"*Generating response...*\")\n",
    "        \n",
    "        # Visual image preview above the textbox\n",
    "        with gr.Row(visible=False) as image_preview_row:\n",
    "            image_preview = gr.Image(\n",
    "                label=\"Image Preview\",\n",
    "                show_label=False,\n",
    "                height=150,\n",
    "                interactive=False,\n",
    "                type=\"filepath\"  # Use filepath for compatibility\n",
    "            )\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Text input\n",
    "            msg = gr.Textbox(\n",
    "                placeholder=\"Describe what you're looking for or ask questions about fashion items...\",\n",
    "                label=\"Your message\",\n",
    "                show_label=False,\n",
    "                scale=8\n",
    "            )\n",
    "            \n",
    "            # Image upload button\n",
    "            image_btn = gr.UploadButton(\n",
    "                \"ðŸ“·\", \n",
    "                file_types=[\"image\"], \n",
    "                file_count=\"single\",\n",
    "                scale=1\n",
    "            )\n",
    "            \n",
    "            # Send button\n",
    "            submit_btn = gr.Button(\"Send\", variant=\"primary\", scale=1)\n",
    "        \n",
    "        # Hidden state for storing the uploaded image\n",
    "        current_image = gr.State(None)\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Clear button\n",
    "            clear_btn = gr.Button(\"Start New Chat\", scale=5)\n",
    "            \n",
    "            # Close server button\n",
    "            close_btn = gr.Button(\"Close Server\", scale=1, variant=\"stop\")\n",
    "        \n",
    "        # Example queries\n",
    "        examples = gr.Examples(\n",
    "            examples=[\n",
    "                [\"I need a casual jacket for cool weather\"],\n",
    "                [\"Looking for a formal dress for a wedding\"],\n",
    "                [\"Show me some comfortable running shoes\"],\n",
    "                [\"I need something professional for job interviews\"]\n",
    "            ],\n",
    "            inputs=msg\n",
    "        )\n",
    "        \n",
    "        # Show preview when image is uploaded\n",
    "        def update_image_preview(file):\n",
    "            if file and hasattr(file, 'name'):\n",
    "                # Show the visual preview\n",
    "                return file.name, gr.Row(visible=True), file.name\n",
    "            return None, gr.Row(visible=False), None\n",
    "        \n",
    "        # Update when image is uploaded - show actual preview\n",
    "        image_btn.upload(\n",
    "            update_image_preview, \n",
    "            image_btn, \n",
    "            [current_image, image_preview_row, image_preview]\n",
    "        )\n",
    "        \n",
    "        # STEP 1: Immediately show user message and image in chat\n",
    "        def add_user_message(message, image_path, chat_history):\n",
    "            # Skip if no input provided\n",
    "            if not message.strip() and not image_path:\n",
    "                return chat_history, message, gr.Button(interactive=True), message\n",
    "            \n",
    "            # Add user message to chat\n",
    "            if message.strip():\n",
    "                chat_history.append([message, None])\n",
    "            elif image_path:\n",
    "                chat_history.append([\"Looking for items similar to this image\", None])\n",
    "            \n",
    "            # Add actual image to chat if present\n",
    "            if image_path:\n",
    "                try:\n",
    "                    # Add image directly to chat history\n",
    "                    chat_history.append([None, image_path])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error adding image to chat: {e}\")\n",
    "                    # Fallback to text if image display fails\n",
    "                    chat_history.append([f\"[Image uploaded]\", None])\n",
    "            \n",
    "            # Clear text input and disable send button\n",
    "            return chat_history, \"\", gr.Button(interactive=False), message\n",
    "        \n",
    "        # STEP 2: Process the message and generate response\n",
    "        def process_message(message, image_path, chat_history):\n",
    "            # Skip if chat history is empty (edge case)\n",
    "            if not chat_history:\n",
    "                return chat_history, gr.Row(visible=False), None, gr.Button(interactive=True), gr.Row(visible=False)\n",
    "            \n",
    "            try:\n",
    "                # Prepare image for processing (if available)\n",
    "                image_data = None\n",
    "                if image_path:\n",
    "                    try:\n",
    "                        from PIL import Image\n",
    "                        image_data = Image.open(image_path)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image: {e}\")\n",
    "                \n",
    "                # Construct query\n",
    "                query = message if message.strip() else \"Find products like this image\"\n",
    "                \n",
    "                # Get response from assistant\n",
    "                responses = chat_fashion_assistant(query, image_data, chat_history)\n",
    "                \n",
    "                # Process responses\n",
    "                if responses and isinstance(responses, list):\n",
    "                    for response in responses:\n",
    "                        if isinstance(response, dict) and \"content\" in response:\n",
    "                            chat_history.append([None, response[\"content\"]])\n",
    "                else:\n",
    "                    # Fallback for invalid response\n",
    "                    chat_history.append([None, \"I'm not sure how to respond to that. Could you try asking another way?\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating response: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                chat_history.append([None, \"Sorry, I encountered an error processing your request. Please try again.\"])\n",
    "            \n",
    "            # Reset image preview, re-enable send button, and hide loading indicator\n",
    "            return chat_history, gr.Row(visible=False), None, gr.Button(interactive=True), gr.Row(visible=False)\n",
    "        \n",
    "        preserved_msg = gr.State(\"\")\n",
    "        \n",
    "        # Split the response into two steps for immediate feedback\n",
    "        submit_btn.click(\n",
    "            fn=add_user_message,  # First immediately show user message\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, msg, submit_btn, preserved_msg],\n",
    "            queue=False  # No queue for immediate UI update\n",
    "        ).then(\n",
    "            fn=process_message,  # Then process the request (can take time)\n",
    "            inputs=[preserved_msg, current_image, chatbot],\n",
    "            outputs=[chatbot, image_preview_row, current_image, submit_btn, loading_indicator],\n",
    "            queue=True  # Use queue for the actual processing\n",
    "        )\n",
    "        \n",
    "        # Same pattern for text input submit\n",
    "        msg.submit(\n",
    "            fn=add_user_message,\n",
    "            inputs=[msg, current_image, chatbot],\n",
    "            outputs=[chatbot, msg, submit_btn, preserved_msg],\n",
    "            queue=False\n",
    "        ).then(\n",
    "            fn=process_message,\n",
    "            inputs=[preserved_msg, current_image, chatbot],\n",
    "            outputs=[chatbot, image_preview_row, current_image, submit_btn, loading_indicator],\n",
    "            queue=True\n",
    "        )\n",
    "        \n",
    "        # Clear chat and reset all states\n",
    "        def clear_all():\n",
    "            return [], None, \"\", gr.Row(visible=False), None, gr.Button(interactive=True)\n",
    "        \n",
    "        clear_btn.click(\n",
    "            clear_all, \n",
    "            None, \n",
    "            [chatbot, current_image, msg, image_preview_row, image_preview, submit_btn], \n",
    "            queue=False\n",
    "        )\n",
    "        \n",
    "        # Close server\n",
    "        def close_server():\n",
    "            app.close()\n",
    "            \n",
    "        close_btn.click(close_server, None, None, queue=False)\n",
    "        \n",
    "    return app\n",
    "\n",
    "# Create and launch the interface\n",
    "shop_gpt = create_fashion_interface()\n",
    "shop_gpt.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
